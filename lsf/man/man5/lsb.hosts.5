
.ad l

.TH lsb.hosts 5 "July 2021" "" ""
.ll 72

.ce 1000
\fBlsb.hosts\fR
.ce 0

.sp 2
The lsb.hosts file contains host-related configuration
information for the server hosts in the cluster. It is also used
to define host groups, host partitions, and compute units.
.sp 2
This file is optional. All sections are optional.
.sp 2
By default, this file is installed in
LSB_CONFDIR/\fIcluster_name\fR/configdir.
.SH Changing lsb.hosts configuration

.sp 2
After making any changes to lsb.hosts, run badmin reconfig to
reconfigure mbatchd.
.sp 2
Parent topic: Configuration files
.sp 2

.ce 1000
\fB#INCLUDE\fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fR#INCLUDE\fR \fR"path-to-file"\fR
.SH Description

.sp 2
Inserts a configuration setting from another file to the current
location. Use this directive to dedicate control of a portion of
the configuration to other users or user groups by providing
write access for the included file to specific users or user
groups, and to ensure consistency of configuration file settings
in different clusters (if you are using the LSF multicluster
capability).
.sp 2
See more information on shared configuration file content in
Administering IBM Spectrum LSF
.sp 2
\fR#INCLUDE\fR can be inserted anywhere in the local
configuration file.
.SH Default

.sp 2
Not defined.
.sp 2

.ce 1000
\fBHost section\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Defines the hosts, host types, and host models used as
server hosts, and contains per-host configuration information. If
this section is not configured, LSF uses all hosts in the cluster
(the hosts listed in lsf.cluster.\fIcluster_name\fR) as server
hosts.
.sp 2
Each host, host model or host type can be configured to do the
following:
.sp 2
*  Limit the maximum number of jobs run in total
.sp 2
*  Limit the maximum number of jobs run by each user
.sp 2
*  Run jobs only under specific load conditions
.sp 2
*  Run jobs only under specific time windows
.sp 2
The entries in a line for a host override the entries in a line
for its model or type.
.sp 2
When you modify the cluster by adding or removing hosts, no
changes are made to lsb.hosts. This does not affect the default
configuration, but if hosts, host models, or host types are
specified in this file, you should check this file whenever you
make changes to the cluster and update it manually if necessary.
.SH Host section structure

.sp 2
The first line consists of keywords identifying the load indices
that you wish to configure on a per-host basis. The keyword
HOST_NAME must be used; the others are optional. Load indices not
listed on the keyword line do not affect scheduling decisions.
.sp 2
Each subsequent line describes the configuration information for
one host, host model or host type. Each line must contain one
entry for each keyword. Use empty parentheses ( ) or a dash (-)
to specify the default value for an entry.
.sp 2

.ce 1000
\fBHOST_NAME\fR
.ce 0

.sp 2
\fIRequired.\fR Specify the name, model, or type of a host, or
the keyword default.
.SH Pattern definition

.sp 2
You can use string literals and special characters when defining
host names. Each entry cannot contain any spaces, as the list
itself is space delimited.
.sp 2
You can use the following special characters to specify hosts:
.sp 2
*  Use square brackets with a hyphen
   ([\fIinteger1\fR-\fIinteger2\fR]) or a colon
   ([\fIinteger1\fR:\fIinteger2\fR]) to define a range of
   non-negative integers at the end of a host name. The first
   integer must be less than the second integer.
.sp 2
*  Use square brackets with commas ([\fIinteger1\fR,
   \fIinteger2\fR ...]) to define individual non-negative
   integers anywhere in the host name.
.sp 2
*  Use square brackets with commas and hyphens or colons (for
   example, [\fIinteger1\fR-\fIinteger2\fR,\fI integer3\fR,
   \fIinteger4\fR:\fIinteger5\fR, \fIinteger6\fR:\fIinteger7\fR])
   to define different ranges of non-negative integers anywhere
   in the host name.
.sp 2
*  Use multiple sets of square brackets (with the supported
   special characters) to define multiple sets of non-negative
   integers anywhere in the host name. For example,
   hostA[1,3]B[1-3] includes hostA1B1, hostA1B2, hostA1B3,
   hostA3B1, hostA3B2, and hostA3B3.
.SH host name

.sp 2
The name of a host defined in lsf.cluster.\fIcluster_name\fR.
.SH host model

.sp 2
A host model defined in lsf.shared.
.SH host type

.sp 2
A host type defined in lsf.shared.
.SH default

.sp 2
The reserved host name default indicates all hosts in the cluster
not otherwise referenced in the section (by name or by listing
its model or type).
.sp 2

.ce 1000
\fBCHKPNT\fR
.ce 0

.sp 2

.SH Description

.sp 2
If C, checkpoint copy is enabled. With checkpoint copy, all
opened files are automatically copied to the checkpoint directory
by the operating system when a process is checkpointed.
.SH Example

.sp 2
HOST_NAME  CHKPNT hostA         C
.br

.SH Compatibility

.sp 2
Checkpoint copy is only supported on Cray systems.
.SH Default

.sp 2
No checkpoint copy
.sp 2

.ce 1000
\fBDISPATCH_WINDOW\fR
.ce 0

.sp 2

.SH Description

.sp 2
The time windows in which jobs from this host, host model, or
host type are dispatched. Once dispatched, jobs are no longer
affected by the dispatch window.
.SH Default

.sp 2
Not defined (always open)
.sp 2

.ce 1000
\fBEXIT_RATE\fR
.ce 0

.sp 2

.SH Description

.sp 2
Specifies a threshold for exited jobs. Specify a number of jobs.
If the number of jobs that exit over a period of time specified
by JOB_EXIT_RATE_DURATION in lsb.params (5 minutes by default)
exceeds the number of jobs you specify as the threshold in this
parameter, LSF invokes LSF_SERVERDIR/eadmin to trigger a host
exception.
.sp 2
EXIT_RATE for a specific host overrides a default
GLOBAL_EXIT_RATE specified in lsb.params.
.SH Example

.sp 2
The following Host section defines a job exit rate of 20 jobs for
all hosts, and an exit rate of 10 jobs on \fRhostA\fR.
.sp 2
Begin Host 
.br
HOST_NAME    MXJ      EXIT_RATE  # Keywords 
.br
Default      !        20 
.br
hostA        !        10 
.br
End Host
.br

.SH Default

.sp 2
Not defined
.sp 2

.ce 1000
\fBJL/U\fR
.ce 0

.sp 2

.SH Description

.sp 2
Per-user job slot limit for the host. Maximum number of job slots
that each user can use on this host.
.SH Example

.sp 2
HOST_NAME  JL/U
.br
hostA         2
.br

.SH Default

.sp 2
Unlimited
.sp 2

.ce 1000
\fBMIG\fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fBMIG=\fRminutes
.SH Description

.sp 2
Enables automatic job migration and specifies the migration
threshold for checkpointable or rerunnable jobs, in minutes.
.sp 2
LSF automatically migrates jobs that have been in the SSUSP state
for more than the specified number of minutes. Specify a value of
0 to migrate jobs immediately upon suspension. The migration
threshold applies to all jobs running on the host.
.sp 2
Job-level command line migration threshold overrides threshold
configuration in application profile and queue. Application
profile configuration overrides queue level configuration. When a
host migration threshold is specified, and is lower than the
value for the job, the queue, or the application, the host value
is used.
.sp 2
Does not affect MultiCluster jobs that are forwarded to a remote
cluster.
.SH Default

.sp 2
Not defined. LSF does not migrate checkpointable or rerunnable
jobs automatically.
.sp 2

.ce 1000
\fBMXJ\fR
.ce 0

.sp 2

.SH Description

.sp 2
The number of job slots on the host.
.sp 2
With MultiCluster resource leasing model, this is the number of
job slots on the host that are available to the local cluster.
.sp 2
Use \fR!\fR to make the number of job slots equal to the number
of CPUs on a host.
.sp 2
For the reserved host name default, \fR!\fR makes the number of
job slots equal to the number of CPUs on all hosts in the cluster
not otherwise referenced in the section.
.sp 2
By default, the number of running and suspended jobs on a host
cannot exceed the number of job slots. If preemptive scheduling
is used, the suspended jobs are not counted as using a job slot.
.sp 2
On multiprocessor hosts, to fully use the CPU resource, make the
number of job slots equal to or greater than the number of
processors.
.SH Default

.sp 2
Unlimited
.sp 2

.ce 1000
\fB\fIload_index\fB\fR
.ce 0

.sp 2

.SH Syntax

.sp 2
load_index loadSched[/loadStop]
.br

.sp 2
Specify \fRio\fR, \fRit\fR, \fRls\fR, \fRmem\fR, \fRpg\fR,
\fRr15s\fR, \fRr1m\fR, \fRr15m\fR, \fRswp\fR, \fRtmp\fR,
\fRut\fR, or a non-shared (host based) dynamic custom external
load index as a column. Specify multiple columns to configure
thresholds for multiple load indices.
.SH Description

.sp 2
Scheduling and suspending thresholds for dynamic load indices
supported by LIM, including external load indices.
.sp 2
Each load index column must contain either the default entry or
two numbers separated by a slash (\fR/\fR), with no white space.
The first number is the scheduling threshold for the load index;
the second number is the suspending threshold.
.sp 2
Queue-level scheduling and suspending thresholds are defined in
lsb.queues. If both files specify thresholds for an index, those
that apply are the most restrictive ones.
.SH Example

.sp 2
HOST_NAME    mem     swp
.br
hostA        100/10  200/30
.sp 2
This example translates into a \fRloadSched\fR condition of
.sp 2
mem>=100 && swp>=200 
.sp 2
and a \fRloadStop\fR condition of
.sp 2
mem < 10 || swp < 30
.SH Default

.sp 2
Not defined
.sp 2

.ce 1000
\fBAFFINITY\fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fBAFFINITY=\fR\fBY\fR | \fBy\fR | \fBN\fR | \fBn\fR | cpu_list
.SH Description

.sp 2
Specifies whether the host can be used to run affinity jobs, and
if so which CPUs are eligible to do so. The syntax accepts Y, N,
a list of CPUs, or a CPU range.
.SH Examples

.sp 2
The following configuration enables affinity scheduling and tells
LSF to use all CPUs on \fRhostA\fR for affinity jobs:
.sp 2
HOST_NAME MXJ r1m AFFINITY
.br
hostA      !  ()   (Y)
.br

.sp 2
The following configuration specifies a CPU list for affinity
scheduling:
.sp 2
HOST_NAME MXJ r1m  AFFINITY
.br
hostA      !  ()   (CPU_LIST="1,3,5,7-10")
.br

.br

.sp 2
This configuration enables affinity scheduling on \fRhostA\fR and
tells LSF to just use CPUs 1,3,5, and CPUs 7-10 to run affinity
jobs.
.sp 2
The following configuration disables affinity scheduling:
.sp 2
HOST_NAME MXJ r1m AFFINITY
.br
hostA      !  ()   (N)
.SH Default

.sp 2
Not defined. Affinity scheduling is not enabled.
.sp 2

.ce 1000
\fBExample of a Host section\fR
.ce 0

.sp 2
Begin Host 
.br
HOST_NAME   MXJ   JL/U r1m         pg       DISPATCH_WINDOW 
.br
hostA        1      -   0.6/1.6   10/20  (5:19:00-1:8:30 20:00-8:30)
.br
Linux       1      -   0.5/2.5 -             23:00-8:00 
.br
default      2      1   0.6/1.6   20/40            ()
.br
End Host
.sp 2
\fRLinux\fR is a host type defined in lsf.shared. This example
\fRHost\fR section configures one host and one host type
explicitly and configures default values for all other
load-sharing hosts.
.sp 2
\fRHostA\fR runs one batch job at a time. A job will only be
started on \fRhostA\fR if the \fRr1m\fR index is below 0.6 and
the \fRpg\fR index is below 10; the running job is stopped if the
\fRr1m\fR index goes above 1.6 or the \fRpg\fR index goes above
20. \fRHostA\fR only accepts batch jobs from 19:00 on Friday
evening until 8:30 Monday morning and overnight from 20:00 to
8:30 on all other days.
.sp 2
For hosts of type \fRLinux\fR, the \fRpg\fR index does not have
host-specific thresholds and such hosts are only available
overnight from 23:00 to 8:00.
.sp 2
The entry with host name default applies to each of the other
hosts in the cluster. Each host can run up to two jobs at the
same time, with at most one job from each user. These hosts are
available to run jobs at all times. Jobs may be started if the
\fRr1m\fR index is below 0.6 and the \fRpg\fR index is below 20.
.sp 2

.ce 1000
\fBHostGroup section\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Defines host groups.
.sp 2
The name of the host group can then be used in other host group,
host partition, and queue definitions, as well as on the command
line. Specifying the name of a host group has exactly the same
effect as listing the names of all the hosts in the group.
.SH Structure

.sp 2
Host groups are specified in the same format as user groups in
lsb.users.
.sp 2
The first line consists of two mandatory keywords, GROUP_NAME and
GROUP_MEMBER, as well as optional keywords, CONDENSE and
GROUP_ADMIN. Subsequent lines name a group and list its
membership.
.sp 2
The sum of all host groups, compute groups, and host partitions
cannot be more than 1024.
.sp 2

.ce 1000
\fBGROUP_NAME\fR
.ce 0

.sp 2

.SH Description

.sp 2
An alphanumeric string representing the name of the host group.
.sp 2
You cannot use the reserved name all, and group names must not
conflict with host names.
.sp 2

.ce 1000
\fBCONDENSE\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Defines condensed host groups.
.sp 2
Condensed host groups are displayed in a condensed output format
for the bhosts and bjobs commands.
.sp 2
If you configure a host to belong to more than one condensed host
group, bjobs can display any of the host groups as execution host
name.
.SH Valid values

.sp 2
Y or N.
.SH Default

.sp 2
\fRN\fR (the specified host group is not condensed)
.sp 2

.ce 1000
\fBGROUP_MEMBER\fR
.ce 0

.sp 2

.SH Description

.sp 2
A space-delimited list of host names or previously defined host
group names, enclosed in one pair of parentheses.
.sp 2
You cannot use more than one pair of parentheses to define the
list.
.sp 2
The names of hosts and host groups can appear on multiple lines
because hosts can belong to multiple groups. The reserved name
all specifies all hosts in the cluster. An exclamation mark
(\fR!\fR) indicates an externally-defined host group, which the
egroup executable retrieves.
.SH Pattern definition

.sp 2
You can use string literals and special characters when defining
host group members. Each entry cannot contain any spaces, as the
list itself is space delimited.
.sp 2
When a leased-in host joins the cluster, the host name is in the
form of \fIhost\fR\fR@\fR\fIcluster\fR. For these hosts, only the
host part of the host name is subject to pattern definitions.
.sp 2
You can use the following special characters to specify host
group members:
.sp 2
*  Use a tilde (\fR~\fR) to exclude specified hosts or host
   groups from the list.
.sp 2
*  Use an asterisk (\fR*\fR) as a wildcard character to represent
   any number of characters.
.sp 2
*  Use square brackets with a hyphen
   ([\fIinteger1\fR-\fIinteger2\fR]) or a colon
   ([\fIinteger1\fR:\fIinteger2\fR]) to define a range of
   non-negative integers anywhere in the host name. The first
   integer must be less than the second integer.
.sp 2
*  Use square brackets with commas ([\fIinteger1\fR,
   \fIinteger2\fR ...]) to define individual non-negative
   integers anywhere in the host name.
.sp 2
*  Use square brackets with commas and hyphens or colons (for
   example, [\fIinteger1\fR-\fIinteger2\fR,\fI integer3\fR,
   \fIinteger4\fR:\fIinteger5\fR, \fIinteger6\fR:\fIinteger7\fR])
   to define different ranges of non-negative integers anywhere
   in the host name.
.sp 2
*  Use multiple sets of square brackets (with the supported
   special characters) to define multiple sets of non-negative
   integers anywhere in the host name. For example,
   hostA[1,3]B[1-3] includes hostA1B1, hostA1B2, hostA1B3,
   hostA3B1, hostA3B2, and hostA3B3.
.SH Restrictions

.sp 2
You cannot define subgroups that contain wildcards and special
characters.
.sp 2

.ce 1000
\fBGROUP_ADMIN\fR
.ce 0

.sp 2

.SH Description

.sp 2
Host group administrators have the ability to open or close the
member hosts for the group they are administering.
.sp 2
the \fRGROUP_ADMIN\fR field is a space-delimited list of user
names or previously defined user group names, enclosed in one
pair of parentheses.
.sp 2
You cannot use more than one pair of parentheses to define the
list.
.sp 2
The names of users and user groups can appear on multiple lines
because users can belong to and administer multiple groups.
.sp 2
Host group administrator rights are inherited. For example, if
the user \fRadmin2\fR is an administrator for host group
\fRhg1\fR and host group \fRhg2\fR is a member of \fRhg1\fR,
\fRadmin2\fR is also an administrator for host group \fRhg2\fR.
.sp 2
When host group administrators (who are not also cluster
administrators) open or close a host, they must specify a comment
with the -C option.
.SH Valid values

.sp 2
Any existing user or user group can be specified. A user group
that specifies an external list is also allowed; however, in this
location, you use the user group name that has been defined with
(!) rather than (!) itself.
.SH Restrictions

.sp 2
*  You cannot specify any wildcards or special characters (for
   example: *, !, $, #, &, ~).
.sp 2
*  You cannot specify an external group (egroup).
.sp 2
*  You cannot use the keyword \fRALL\fR and you cannot administer
   any group that has ALL as its members.
.sp 2
*  User names and user group names cannot have spaces.
.sp 2

.ce 1000
\fBExample HostGroup sections\fR
.ce 0

.sp 2

.SH Example 1

.sp 2
Begin HostGroup 
.br
GROUP_NAME  GROUP_MEMBER GROUP_ADMIN
.br
groupA      (hostA hostD) (user1 user10)
.br
groupB      (hostF groupA hostK) ()
.br
groupC      (!) ()
.br
End HostGroup
.sp 2
This example defines three host groups:
.sp 2
*  \fRgroupA\fR includes \fRhostA\fR and \fRhostD\fR and can be
   administered by user1 and user10.
.sp 2
*  \fRgroupB\fR includes \fRhostF\fR and \fRhostK\fR, along with
   all hosts in \fRgroupA\fR. It has no administrators (only the
   cluster administrator can control the member hosts).
.sp 2
*  The group membership of \fRgroupC\fR is defined externally and
   retrieved by the egroup executable.
.SH Example 2

.sp 2
Begin HostGroup 
.br
GROUP_NAME   GROUP_MEMBER GROUP_ADMIN
.br
groupA       (all) ()
.br
groupB       (groupA ~hostA ~hostB) (user11 user14)
.br
groupC       (hostX hostY hostZ) ()
.br
groupD       (groupC ~hostX) usergroupB
.br
groupE       (all ~groupC ~hostB) ()
.br
groupF       (hostF groupC hostK) ()
.br
End HostGroup
.sp 2
This example defines the following host groups:
.sp 2
*  \fRgroupA\fR contains all hosts in the cluster and is
   administered by the cluster administrator.
.sp 2
*  \fRgroupB\fR contains all the hosts in the cluster except for
   \fRhostA\fR and \fRhostB\fR and is administered by user11 and
   user14.
.sp 2
*  \fRgroupC\fR contains only \fRhostX\fR, \fRhostY\fR, and
   \fRhostZ\fR and is administered by the cluster administrator.
.sp 2
*  \fRgroupD\fR contains the hosts in \fRgroupC\fR except for
   \fRhostX\fR. Note that \fRhostX\fR must be a member of host
   group \fRgroupC\fR to be excluded from \fRgroupD\fR.
   \fRusergroupB\fR is the administrator for \fRgroupD\fR.
.sp 2
*  \fRgroupE\fR contains all hosts in the cluster excluding the
   hosts in \fRgroupC\fR and \fRhostB\fR and is administered by
   the cluster administrator.
.sp 2
*  \fRgroupF\fR contains \fRhostF\fR, \fRhostK\fR, and the 3
   hosts in \fRgroupC\fR and is administered by the cluster
   administrator.
.SH Example 3

.sp 2
Begin HostGroup 
.br
GROUP_NAME   CONDENSE   GROUP_MEMBER GROUP_ADMIN
.br
groupA          N       (all) ()
.br
groupB          N       (hostA, hostB) (usergroupC user1)
.br
groupC          Y       (all)()
.br
End HostGroup
.sp 2
This example defines the following host groups:
.sp 2
*  \fRgroupA\fR shows uncondensed output and contains all hosts
   in the cluster and is administered by the cluster
   administrator.
.sp 2
*  \fRgroupB\fR shows uncondensed output, and contains
   \fRhostA\fR and \fRhostB\fR. It is administered by all members
   of usergroupC and user1.
.sp 2
*  \fRgroupC\fR shows condensed output and contains all hosts in
   the cluster and is administered by the cluster administrator.
.SH Example 4

.sp 2
Begin HostGroup 
.br
GROUP_NAME CONDENSE GROUP_MEMBER GROUP_ADMIN
.br
groupA          Y (host*) (user7)
.br
groupB          N (*A) ()
.br
groupC          N (hostB* ~hostB[1-50]) ()
.br
groupD          Y (hostC[1:50] hostC[101:150]) (usergroupJ)
.br
groupE          N (hostC[51-100] hostC[151-200]) ()
.br
groupF          Y (hostD[1,3] hostD[5-10]) ()
.br
groupG          N (hostD[11-50] ~hostD[15,20,25] hostD2) ()
.br
groupH          Y (hostX[1:10]Y[1:10]) ()
.br
End HostGroup
.sp 2
This example defines the following host groups:
.sp 2
*  \fRgroupA\fR shows condensed output, and contains all hosts
   starting with the string \fRhost\fR. It is administered by
   user7.
.sp 2
*  \fRgroupB\fR shows uncondensed output, and contains all hosts
   ending with the string \fRA\fR, such as \fRhostA\fR and is
   administered by the cluster administrator.
.sp 2
*  \fRgroupC\fR shows uncondensed output, and contains all hosts
   starting with the string \fRhostB\fR except for the hosts from
   \fRhostB1\fR to \fRhostB50\fR and is administered by the
   cluster administrator.
.sp 2
*  \fRgroupD\fR shows condensed output, and contains all hosts
   from \fRhostC1\fR to \fRhostC50\fR and all hosts from
   \fRhostC101\fR to \fRhostC150\fR and is administered by the
   the members of \fRusergroupJ\fR.
.sp 2
*  \fRgroupE\fR shows uncondensed output, and contains all hosts
   from \fRhostC51\fR to \fRhostC100\fR and all hosts from
   \fRhostC151\fR to \fRhostC200\fR and is administered by the
   cluster administrator.
.sp 2
*  \fRgroupF\fR shows condensed output, and contains
   \fRhostD1\fR, \fRhostD3\fR, and all hosts from \fRhostD5\fR to
   \fRhostD10 and is administered by the cluster
   administrator\fR.
.sp 2
*  \fRgroupG\fR shows uncondensed output, and contains all hosts
   from \fRhostD11\fR to \fRhostD50\fR except for \fRhostD15\fR,
   \fRhostD20\fR, and \fRhostD25\fR. \fRgroupG\fR also includes
   \fRhostD2\fR. It is administered by the cluster administrator.
.sp 2

.ce 1000
\fBHostPartition section\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Used with host partition user-based fairshare
scheduling. Defines a host partition, which defines a user-based
fairshare policy at the host level.
.sp 2
Configure multiple sections to define multiple partitions.
.sp 2
The members of a host partition form a host group with the same
name as the host partition.
.sp 2
\fBRestriction: \fRYou cannot use host partitions and host
preference simultaneously.
.SH Limitations on queue configuration

.sp 2
*  If you configure a host partition, you cannot configure
   fairshare at the queue level.
.sp 2
*  If a queue uses a host that belongs to a host partition, it
   should not use any hosts that don’t belong to that partition.
   All the hosts in the queue should belong to the same
   partition. Otherwise, you might notice unpredictable
   scheduling behavior:
.sp 2
   *  Jobs in the queue sometimes may be dispatched to the host
      partition even though hosts not belonging to any host
      partition have a lighter load.
.sp 2
   *  If some hosts belong to one host partition and some hosts
      belong to another, only the priorities of one host
      partition are used when dispatching a parallel job to hosts
      from more than one host partition.
.SH Shared resources and host partitions

.sp 2
*  If a resource is shared among hosts included in host
   partitions and hosts that are not included in any host
   partition, jobs in queues that use the host partitions will
   always get the shared resource first, regardless of queue
   priority.
.sp 2
*  If a resource is shared among host partitions, jobs in queues
   that use the host partitions listed first in the
   \fRHostPartition \fRsection of lsb.hosts will always have
   priority to get the shared resource first. To allocate shared
   resources among host partitions, LSF considers host partitions
   in the order they are listed in lsb.hosts.
.SH Structure

.sp 2
Each host partition always consists of 3 lines, defining the name
of the partition, the hosts included in the partition, and the
user share assignments.
.sp 2

.ce 1000
\fBHPART_NAME \fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fRHPART_NAME\fR=\fIpartition_name\fR
.SH Description

.sp 2
Specifies the name of the partition. The name must be 59
characters or less.
.sp 2

.ce 1000
\fBHOSTS \fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fRHOSTS\fR=[[~]\fIhost_name | \fR[~]\fIhost_group |\fR all]...
.SH Description

.sp 2
Specifies the hosts in the partition, in a space-separated list.
.sp 2
A host cannot belong to multiple partitions.
.sp 2
A host group cannot be empty.
.sp 2
Hosts that are not included in any host partition are controlled
by the FCFS scheduling policy instead of the fairshare scheduling
policy.
.sp 2
Optionally, use the reserved host name all to configure a single
partition that applies to all hosts in a cluster.
.sp 2
Optionally, use the not operator (~) to exclude hosts or host
groups from the list of hosts in the host partition.
.SH Examples

.sp 2
\fRHOSTS=all ~hostK ~hostM\fR
.sp 2
The partition includes all the hosts in the cluster, except for
\fRhostK\fR and \fRhostM\fR.
.sp 2
HOSTS=groupA ~hostL
.sp 2
The partition includes all the hosts in host group \fRgroupA\fR
except for \fRhostL\fR.
.sp 2

.ce 1000
\fBUSER_SHARES\fR
.ce 0

.sp 2

.SH Syntax

.sp 2
\fRUSER_SHARES\fR=[\fIuser\fR, \fInumber_shares\fR]...
.SH Description

.sp 2
Specifies user share assignments
.sp 2
*  Specify at least one user share assignment.
.sp 2
*  Enclose each user share assignment in square brackets, as
   shown.
.sp 2
*  Separate a list of multiple share assignments with a space
   between the square brackets.
.sp 2
*  \fIuser—\fRSpecify users who are also configured to use the
   host partition. You can assign the shares:
.sp 2
   *  To a single user (specify \fIuser_name\fR). To specify a
      Windows user account, include the domain name in uppercase
      letters (\fIDOMAIN_NAME\fR\\fIuser_name\fR).
.sp 2
   *  To users in a group, individually (specify
      \fIgroup_name\fR@) or collectively (specify
      \fIgroup_name\fR). To specify a Windows user group, include
      the domain name in uppercase letters
      (\fIDOMAIN_NAME\fR\\fIgroup_name\fR).
.sp 2
   *  To users not included in any other share assignment,
      individually (specify the keyword default) or collectively
      (specify the keyword others).
.sp 2
By default, when resources are assigned collectively to a group,
the group members compete for the resources according to FCFS
scheduling. You can use hierarchical fairshare to further divide
the shares among the group members.
.sp 2
When resources are assigned to members of a group individually,
the share assignment is recursive. Members of the group and of
all subgroups always compete for the resources according to FCFS
scheduling, regardless of hierarchical fairshare policies.
.sp 2
*  \fInumber_shares\fR
.sp 2
   *  Specify a positive integer representing the number of
      shares of the cluster resources assigned to the user.
.sp 2
   *  The number of shares assigned to each user is only
      meaningful when you compare it to the shares assigned to
      other users or to the total number of shares. The total
      number of shares is just the sum of all the shares assigned
      in each share assignment.
.SH Example of a HostPartition section

.sp 2
Begin HostPartition
.br
HPART_NAME = Partition1 HOSTS = hostA hostB USER_SHARES = 
.br
[groupA@, 3] [groupB, 7] [default, 1] 
.br
End HostPartition
.sp 2

.ce 1000
\fBComputeUnit section\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Defines compute units.
.sp 2
Once defined, the compute unit can be used in other compute unit
and queue definitions, as well as in the command line. Specifying
the name of a compute unit has the same effect as listing the
names of all the hosts in the compute unit.
.sp 2
Compute units are similar to host groups, with the added feature
of granularity allowing the construction of structures that mimic
the network architecture. Job scheduling using compute unit
resource requirements effectively spreads jobs over the cluster
based on the configured compute units.
.sp 2
To enforce consistency, compute unit configuration has the
following requirements:
.sp 2
*  Hosts and host groups appear in the finest granularity compute
   unit type, and nowhere else.
.sp 2
*  Hosts appear in only one compute unit of the finest
   granularity.
.sp 2
*  All compute units of the same type have the same type of
   compute units (or hosts) as members.
.SH Structure

.sp 2
Compute units are specified in the same format as host groups in
lsb.hosts.
.sp 2
The first line consists of three mandatory keywords, NAME,
MEMBER, and TYPE, as well as optional keywords CONDENSE and
ADMIN. Subsequent lines name a compute unit and list its
membership.
.sp 2
The sum of all host groups, compute groups, and host partitions
cannot be more than 1024.
.sp 2

.ce 1000
\fBNAME\fR
.ce 0

.sp 2

.SH Description

.sp 2
An alphanumeric string representing the name of the compute unit.
.sp 2
You cannot use the reserved names all, allremote, others, and
default. Compute unit names must not conflict with host names,
host partitions, or host group names.
.sp 2

.ce 1000
\fBCONDENSE\fR
.ce 0

.sp 2

.SH Description

.sp 2
Optional. Defines condensed compute units.
.sp 2
Condensed compute units are displayed in a condensed output
format for the bhosts and bjobs commands. The condensed compute
unit format includes the slot usage for each compute unit.
.SH Valid values

.sp 2
Y or N.
.SH Default

.sp 2
\fRN\fR (the specified host group is not condensed)
.sp 2

.ce 1000
\fBMEMBER\fR
.ce 0

.sp 2

.SH Description

.sp 2
A space-delimited list of host names or previously defined
compute unit names, enclosed in one pair of parentheses.
.sp 2
You cannot use more than one pair of parentheses to define the
list.
.sp 2
The names of hosts and host groups can appear only once, and only
in a compute unit type of the finest granularity.
.sp 2
An exclamation mark (\fR!\fR) indicates an externally-defined
host group, which the egroup executable retrieves.
.SH Pattern definition

.sp 2
You can use string literals and special characters when defining
compute unit members. Each entry cannot contain any spaces, as
the list itself is space delimited.
.sp 2
You can use the following special characters to specify host and
host group compute unit members:
.sp 2
*  Use a tilde (\fR~\fR) to exclude specified hosts or host
   groups from the list.
.sp 2
*  Use an asterisk (\fR*\fR) as a wildcard character to represent
   any number of characters.
.sp 2
*  Use square brackets with a hyphen
   ([\fIinteger1\fR-\fIinteger2\fR]) or a colon
   ([\fIinteger1\fR:\fIinteger2\fR]) to define a range of
   non-negative integers anywhere in the host name. The first
   integer must be less than the second integer.
.sp 2
*  Use square brackets with commas ([\fIinteger1\fR,
   \fIinteger2\fR...]) to define individual non-negative integers
   anywhere in the host name.
.sp 2
*  Use square brackets with commas and hyphens or colons (for
   example, [\fIinteger1\fR-\fIinteger2\fR,\fI integer3\fR,
   \fIinteger4\fR:\fIinteger5\fR, \fIinteger6\fR:\fIinteger7\fR])
   to define different ranges of non-negative integers anywhere
   in the host name.
.sp 2
*  Use multiple sets of square brackets (with the supported
   special characters) to define multiple sets of non-negative
   integers anywhere in the host name. For example,
   hostA[1,3]B[1-3] includes hostA1B1, hostA1B2, hostA1B3,
   hostA3B1, hostA3B2, and hostA3B3.
.SH Restrictions

.sp 2
*  Compute unit names cannot be used in compute units of the
   finest granularity.
.sp 2
*  You cannot include host or host group names except in compute
   units of the finest granularity.
.sp 2
*  You must not skip levels of granularity. For example:
.sp 2
   If lsb.params contains \fRCOMPUTE_UNIT_TYPES=enclosure rack
   cabinet\fR then a compute unit of type \fRcabinet\fR can
   contain compute units of type \fRrack\fR, but not of type
   \fRenclosure\fR.
.sp 2
*  The keywords all, allremote, all@cluster, other and default
   cannot be used when defining compute units.
.sp 2

.ce 1000
\fBTYPE\fR
.ce 0

.sp 2

.SH Description

.sp 2
The type of the compute unit, as defined in the
\fBCOMPUTE_UNIT_TYPES\fR parameter of lsb.params.
.sp 2

.ce 1000
\fBADMIN\fR
.ce 0

.sp 2

.SH Description

.sp 2
Compute unit administrators have the ability to open or close the
member hosts for the compute unit they are administering.
.sp 2
the \fRADMIN\fR field is a space-delimited list of user names or
previously defined user group names, enclosed in one pair of
parentheses.
.sp 2
You cannot use more than one pair of parentheses to define the
list.
.sp 2
The names of users and user groups can appear on multiple lines
because users can belong to and administer multiple compute
units.
.sp 2
Compute unit administrator rights are inherited. For example, if
the user admin2 is an administrator for compute unit cu1 and
compute unit cu2 is a member of cu1, admin2 is also an
administrator for compute unit cu2.
.sp 2
When compute unit administrators (who are not also cluster
administrators) open or close a host, they must specify a comment
with the -C option.
.SH Valid values

.sp 2
Any existing user or user group can be specified. A user group
that specifies an external list is also allowed; however, in this
location, you use the user group name that has been defined with
(!) rather than (!) itself.
.SH Restrictions

.sp 2
*  You cannot specify any wildcards or special characters (for
   example: *, !, $, #, &, ~).
.sp 2
*  You cannot specify an external group (egroup).
.sp 2
*  You cannot use the keyword \fRALL\fR and you cannot administer
   any group that has ALL as its members.
.sp 2
*  User names and user group names cannot have spaces.
.sp 2

.ce 1000
\fBExample ComputeUnit sections\fR
.ce 0

.sp 2

.SH Example 1

.sp 2
(For the lsb.params entry \fRCOMPUTE_UNIT_TYPES=enclosure rack
cabinet\fR)
.sp 2
Begin ComputeUnit 
.br
NAME   MEMBER        TYPE
.br
encl1  (host1 host2) enclosure
.br
encl2  (host3 host4) enclosure
.br
encl3  (host5 host6) enclosure
.br
encl4  (host7 host8) enclosure
.br
rack1  (encl1 encl2) rack
.br
rack2  (encl3 encl4) rack
.br
cbnt1  (rack1 rack2) cabinet
.br
End ComputeUnit
.sp 2
This example defines seven compute units:
.sp 2
*  \fRencl1\fR, \fRencl2\fR, \fRencl3\fR and \fRencl4\fR are the
   finest granularity, and each contain two hosts.
.sp 2
*  \fRrack1\fR is of coarser granularity and contains two levels.
   At the enclosure level \fRrack1\fR contains \fRencl1\fR and
   \fRencl2\fR. At the lowest level \fRrack1\fR contains
   \fRhost1\fR, \fRhost2\fR, \fRhost3\fR, and \fRhost4\fR.
.sp 2
*  \fRrack2\fR has the same structure as \fRrack1\fR, and
   contains \fRencl3\fR and \fRencl4\fR.
.sp 2
*  \fRcbnt1\fR contains two racks (\fRrack1\fR and \fRrack2\fR),
   four enclosures (\fRencl1\fR, \fRencl2\fR, \fRencl3\fR, and
   \fRencl4\fR) and all eight hosts. Compute unit \fRcbnt1\fR is
   the coarsest granularity in this example.
.SH Example 2

.sp 2
(For the lsb.params entry \fRCOMPUTE_UNIT_TYPES=enclosure rack
cabinet\fR)
.sp 2
Begin ComputeUnit 
.br
NAME  CONDENSE MEMBER                   TYPE      ADMIN
.br
encl1 Y        (hg123 ~hostA ~hostB)    enclosure (user11 user14)
.br
encl2 Y        (hg456)                  enclosure ()
.br
encl3 N        (hostA hostB)            enclosure usergroupB
.br
encl4 N        (hgroupX ~hostB)         enclosure ()
.br
encl5 Y        (hostC* ~hostC[101-150]) enclosure usergroupJ
.br
encl6 N        (hostC[101-150])         enclosure ()
.br
rack1 Y        (encl1 encl2 encl3)      rack      ()
.br
rack2 N        (encl4 encl5)            rack      usergroupJ
.br
rack3 N        (encl6)                  rack      ()
.br
cbnt1 Y        (rack1 rack2)            cabinet   ()
.br
cbnt2 N        (rack3)                  cabinet   user14
.br
End ComputeUnit
.sp 2
This example defines 11 compute units:
.sp 2
*  All six enclosures (finest granularity) contain only hosts and
   host groups. All three racks contain only enclosures. Both
   cabinets (coarsest granularity) contain only racks.
.sp 2
*  \fRencl1\fR contains all the hosts in host group \fRhg123\fR
   except for \fRhostA\fR and \fRhostB\fR and is administered by
   user11 and user14. Note that \fRhostA\fR and \fRhostB\fR must
   be members of host group \fRhg123\fR to be excluded from
   \fRencl1\fR. \fRencl1\fR shows condensed output.
.sp 2
*  \fRencl2\fR contains host group \fRhg456\fR and is
   administered by the cluster administrator. \fRencl2\fR shows
   condensed output.
.sp 2
*  \fRencl3\fR contains \fRhostA\fR and \fRhostB\fR.
   \fRusergroupB\fR is the administrator for \fRencl3\fR.
   \fRencl3\fR shows uncondensed output.
.sp 2
*  \fRencl4\fR contains host group \fRhgroupX\fR except for
   \fRhostB\fR. Since each host can appear in only one enclosure
   and \fRhostB\fR is already in \fRencl3\fR, it cannot be in
   \fRencl4\fR. \fRencl4\fR is administered by the cluster
   administrator. \fRencl4\fR shows uncondensed output.
.sp 2
*  \fRencl5\fR contains all hosts starting with the string
   \fRhostC\fR except for hosts \fRhostC101\fR to \fRhostC150\fR,
   and is administered by \fRusergroupJ\fR. \fRencl5\fR shows
   condensed output.
.sp 2
*  \fRrack1\fR contains \fRencl1\fR, \fRencl2\fR, and
   \fRencl3\fR. \fRrack1\fR shows condensed output.
.sp 2
*  \fRrack2\fR contains \fRencl4\fR, and \fRencl5\fR. \fRrack2\fR
   shows uncondensed output.
.sp 2
*  \fRrack3\fR contains \fRencl6\fR. \fRrack3\fR shows
   uncondensed output.
.sp 2
*  cbnt1 contains \fRrack1\fR and \fRrack2\fR. \fRcbnt1\fR shows
   condensed output.
.sp 2
*  \fRcbnt2\fR contains \fRrack3\fR. Even though \fRrack3\fR only
   contains encl6, \fRcbnt3\fR cannot contain \fRencl6\fR
   directly because that would mean skipping the level associated
   with compute unit type \fRrack\fR. \fRcbnt2\fR shows
   uncondensed output.
.sp 2

.ce 1000
\fBAutomatic time-based configuration\fR
.ce 0

.sp 2
Variable configuration is used to automatically change LSF
configuration based on time windows. You define automatic
configuration changes in lsb.hosts by using if-else constructs
and time expressions. After you change the files, reconfigure the
cluster with the badmin reconfig command.
.sp 2
The expressions are evaluated by LSF every 10 minutes based on
mbatchd start time. When an expression evaluates true, LSF
dynamically changes the configuration based on the associated
configuration statements. Reconfiguration is done in real time
without restarting mbatchd, providing continuous system
availability.
.SH Example

.sp 2
In the following example, the #if, #else, #endif are not
interpreted as comments by LSF but as if-else constructs.
.sp 2
Begin Host
.br
HOST_NAME   r15s   r1m   pg
.br
host1       3/5    3/5   12/20
.br
#if time(5:16:30-1:8:30 EDT 20:00-8:30 EDT)
.br
host2       3/5    3/5   12/20
.br
#else
.br
host2       2/3    2/3   10/12
.br
#endif
.br
host3       3/5    3/5   12/20
.br
End Host
.sp 2
Specifying the time zone is optional. If you do not specify a
time zone, LSF uses the local system time zone. LSF supports all
standard time zone abbreviations.
.TH "lsb_pendreason" 3 "10 Jun 2021" "Version 10.1" "IBM Spectrum LSF 10.1 C API Reference" \" -*- nroff -*-
.ad l
.nh
.SH NAME
lsb_pendreason \- lsb_pendreason 
Explains why a job is pending.
.PP
Use \fBlsb_pendreason\fP to determine why a job is pending. Each pending reason is associated with one or more hosts.
.PP
\fB#include <lsf/lsbatch.h>\fP
.PP
\fB char *lsb_pendreason (int numReasons, int *rsTb, struct \fBjobInfoHead\fP *jInfoH, struct \fBloadIndexLog\fP *ld, int clusterId)\fP
.PP
.SH "Parameters:"
\fInumReasons\fP The number of reasons in the rsTb reason table. 
.br
\fI*rsTb\fP The reason table. Each entry in the table contains one of \fBpending_reasons\fP 
.br
\fI*jInfoH\fP jInfoH contains job information. 
.br
\fI*ld\fP From \fBlsb_suspreason\fP, when reasons is SUSP_LOAD_REASON, ld is used to determine the name of any external load indices. ld uses the most recent load index log in the lsb.events file. 
.br
\fIclusterId\fP MultiCluster cluster ID. If clusterId is greater than or equal to 0, the job is a pending remote job, and \fBlsb_pendreason\fP checks for host_name@cluster_name. If host name is needed, it should be found in jInfoH->remoteHosts. If the remote host name is not available, the constant string remoteHost is used.
.PP
.SH "Data Structures:" 
.PP
\fBjobInfoHead\fP 
.br
\fBloadIndexLog\fP
.PP
.SH "Define Statements:" 
.PP
\fBpending_reasons\fP 
.br
\fBsuspending_reasons\fP 
.br
\fBsuspending_subreasons\fP
.PP
.SH "Returns:"
char *:reasons 
.br
 The function is successful. It returns a reason why the job is pending. 
.PP
NULL 
.br
 The function fails. The reason code is bad.
.PP
.SH "Errors:" 
.PP
If no PEND reason is found, the function fails and lsberrno is set to indicate the error.
.PP
.SH "Equivalent line command:" 
.PP
bjobs -p
.PP
.SH "Files:" 
.PP
${LSF_ENVDIR:-/etc}/lsf.conf
.PP
.SH "See also:"
\fBlsb_geteventrec\fP 
.PP

.ad l
.nh
.SH NAME
jobInfoHead \- job information head.  

.PP
.SH SYNOPSIS
.br
.PP
.SS "Data Fields"

.in +1c
.ti -1c
.RI "int \fBnumJobs\fP"
.br
.ti -1c
.RI "LS_LONG_INT * \fBjobIds\fP"
.br
.ti -1c
.RI "int \fBnumHosts\fP"
.br
.ti -1c
.RI "char ** \fBhostNames\fP"
.br
.ti -1c
.RI "int \fBnumClusters\fP"
.br
.ti -1c
.RI "char ** \fBclusterNames\fP"
.br
.ti -1c
.RI "int * \fBnumRemoteHosts\fP"
.br
.ti -1c
.RI "char *** \fBremoteHosts\fP"
.br
.ti -1c
.RI "int \fBstrTableCnt\fP"
.br
.ti -1c
.RI "\fBreasonRefStrTab\fP * \fBstrRefTable\fP"
.br
.ti -1c
.RI "int \fBreasonMsgCnt\fP"
.br
.ti -1c
.RI "\fBLSB_ReasonMsgConf\fP * \fBreasonMsgConf\fP"
.br
.ti -1c
.RI "int \fBrsrcMsgCnt\fP"
.br
.ti -1c
.RI "\fBLSB_RsrcConf\fP * \fBrsrcMsgConf\fP"
.br
.ti -1c
.RI "struct extJobInfoHead \fBext\fP"
.br
.in -1c
.SH "Detailed Description"
.PP 
job information head. 
.SH "Field Documentation"
.PP 
.SS "int \fBjobInfoHead::numJobs\fP"
.PP
The number of jobs in the connection. 
.PP

.SS "LS_LONG_INT* \fBjobInfoHead::jobIds\fP"
.PP
An array of job identification numbers in the connection. 
.PP

.SS "int \fBjobInfoHead::numHosts\fP"
.PP
The number of hosts in the connection. 
.PP

.SS "char** \fBjobInfoHead::hostNames\fP"
.PP
An array of host names in the connection. 
.PP

.SS "int \fBjobInfoHead::numClusters\fP"
.PP
The number of clusters in the connection. 
.PP

.SS "char** \fBjobInfoHead::clusterNames\fP"
.PP
An array of cluster names in the connection. 
.PP

.SS "int* \fBjobInfoHead::numRemoteHosts\fP"
.PP
The number of remoteHosts in the connection. 
.PP

.SS "char*** \fBjobInfoHead::remoteHosts\fP"
.PP
An array of remoteHost names in the connection. 
.PP

.SS "int \fBjobInfoHead::strTableCnt\fP"
.PP
The number of string tables used by pending reasons. 
.PP

.SS "\fBreasonRefStrTab\fP* \fBjobInfoHead::strRefTable\fP"
.PP
An array of string tables used by pending reasons. 
.PP

.SS "int \fBjobInfoHead::reasonMsgCnt\fP"
.PP
The customized pending reason conf number. 
.PP

.SS "\fBLSB_ReasonMsgConf\fP* \fBjobInfoHead::reasonMsgConf\fP"
.PP
The customized pending reason conf array. 
.PP

.SS "int \fBjobInfoHead::rsrcMsgCnt\fP"
.PP
The total number of resource message configurations. 
.PP

.SS "\fBLSB_RsrcConf\fP* \fBjobInfoHead::rsrcMsgConf\fP"
.PP
The resource message conf array. 
.PP

.SS "struct extJobInfoHead \fBjobInfoHead::ext\fP"
.PP
add all new parameters in this struct for xdr_complex 
.PP


.ad l
.nh
.SH NAME
loadIndexLog \- load index log.  

.PP
.SH SYNOPSIS
.br
.PP
.SS "Data Fields"

.in +1c
.ti -1c
.RI "int \fBnIdx\fP"
.br
.ti -1c
.RI "char ** \fBname\fP"
.br
.in -1c
.SH "Detailed Description"
.PP 
load index log. 
.SH "Field Documentation"
.PP 
.SS "int \fBloadIndexLog::nIdx\fP"
.PP
The number of load indices. 
.PP
.SS "char** \fBloadIndexLog::name\fP"
.PP
The array of load index names. 
.PP


.ad l
.nh
.SH NAME
pending_reasons \- Each entry in the table contains one of the following pending reasons.  

.PP
.SS "Defines"

.in +1c
.ti -1c
.RI "#define \fBPEND_JOB_REASON\fP   0"
.br
.ti -1c
.RI "#define \fBPEND_JOB_NEW\fP   1"
.br
.ti -1c
.RI "#define \fBPEND_JOB_START_TIME\fP   2"
.br
.ti -1c
.RI "#define \fBPEND_JOB_DEPEND\fP   3"
.br
.ti -1c
.RI "#define \fBPEND_JOB_DEP_INVALID\fP   4"
.br
.ti -1c
.RI "#define \fBPEND_JOB_MIG\fP   5"
.br
.ti -1c
.RI "#define \fBPEND_JOB_PRE_EXEC\fP   6"
.br
.ti -1c
.RI "#define \fBPEND_JOB_NO_FILE\fP   7"
.br
.ti -1c
.RI "#define \fBPEND_JOB_ENV\fP   8"
.br
.ti -1c
.RI "#define \fBPEND_JOB_PATHS\fP   9"
.br
.ti -1c
.RI "#define \fBPEND_JOB_OPEN_FILES\fP   10"
.br
.ti -1c
.RI "#define \fBPEND_JOB_EXEC_INIT\fP   11"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RESTART_FILE\fP   12"
.br
.ti -1c
.RI "#define \fBPEND_JOB_DELAY_SCHED\fP   13"
.br
.ti -1c
.RI "#define \fBPEND_JOB_SWITCH\fP   14"
.br
.ti -1c
.RI "#define \fBPEND_JOB_DEP_REJECT\fP   15"
.br
.ti -1c
.RI "#define \fBPEND_JOB_JS_DISABLED\fP   16"
.br
.ti -1c
.RI "#define \fBPEND_JOB_NO_PASSWD\fP   17"
.br
.ti -1c
.RI "#define \fBPEND_JOB_LOGON_FAIL\fP   18"
.br
.ti -1c
.RI "#define \fBPEND_JOB_MODIFY\fP   19"
.br
.ti -1c
.RI "#define \fBPEND_JOB_TIME_INVALID\fP   20"
.br
.ti -1c
.RI "#define \fBPEND_TIME_EXPIRED\fP   21"
.br
.ti -1c
.RI "#define \fBPEND_JOB_REQUEUED\fP   23"
.br
.ti -1c
.RI "#define \fBPEND_WAIT_NEXT\fP   24"
.br
.ti -1c
.RI "#define \fBPEND_JGRP_HOLD\fP   25"
.br
.ti -1c
.RI "#define \fBPEND_JGRP_INACT\fP   26"
.br
.ti -1c
.RI "#define \fBPEND_JGRP_WAIT\fP   27"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RCLUS_UNREACH\fP   28"
.br
.ti -1c
.RI "#define \fBPEND_JOB_QUE_REJECT\fP   29"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RSCHED_START\fP   30"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RSCHED_ALLOC\fP   31"
.br
.ti -1c
.RI "#define \fBPEND_JOB_FORWARDED\fP   32"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RMT_ZOMBIE\fP   33"
.br
.ti -1c
.RI "#define \fBPEND_JOB_ENFUGRP\fP   34"
.br
.ti -1c
.RI "#define \fBPEND_SYS_UNABLE\fP   35"
.br
.ti -1c
.RI "#define \fBPEND_JGRP_RELEASE\fP   36"
.br
.ti -1c
.RI "#define \fBPEND_HAS_RUN\fP   37"
.br
.ti -1c
.RI "#define \fBPEND_JOB_ARRAY_JLIMIT\fP   38"
.br
.ti -1c
.RI "#define \fBPEND_CHKPNT_DIR\fP   39"
.br
.ti -1c
.RI "#define \fBPEND_CHUNK_FAIL\fP   40"
.br
.ti -1c
.RI "#define \fBPEND_JOB_SLA_MET\fP   41"
.br
.ti -1c
.RI "#define \fBPEND_JOB_APP_NOEXIST\fP   42"
.br
.ti -1c
.RI "#define \fBPEND_APP_PROCLIMIT\fP   43"
.br
.ti -1c
.RI "#define \fBPEND_EGO_NO_HOSTS\fP   44"
.br
.ti -1c
.RI "#define \fBPEND_JGRP_JLIMIT\fP   45"
.br
.ti -1c
.RI "#define \fBPEND_PREEXEC_LIMIT\fP   46"
.br
.ti -1c
.RI "#define \fBPEND_REQUEUE_LIMIT\fP   47"
.br
.ti -1c
.RI "#define \fBPEND_BAD_RESREQ\fP   48"
.br
.ti -1c
.RI "#define \fBPEND_RSV_INACTIVE\fP   49"
.br
.ti -1c
.RI "#define \fBPEND_WAITING_RESUME\fP   50"
.br
.ti -1c
.RI "#define \fBPEND_SLOT_COMPOUND\fP   51"
.br
.ti -1c
.RI "#define \fBPEND_SLOT_ALTERNATIVE\fP   52"
.br
.ti -1c
.RI "#define \fBPEND_FANOUT_FAIL\fP   53"
.br
.ti -1c
.RI "#define \fBPEND_SLOT_LIST_JOB_LEVEL\fP   54"
.br
.ti -1c
.RI "#define \fBPEND_JOB_SIZE_LIST_APP_LEVEL\fP   55"
.br
.ti -1c
.RI "#define \fBPEND_JOB_SIZE_LIST_QUEUE_LEVEL\fP   56"
.br
.ti -1c
.RI "#define \fBPEND_NOTMATCH_NBLOCK\fP   57"
.br
.ti -1c
.RI "#define \fBPEND_NLIST_NBLOCK_JOB\fP   58"
.br
.ti -1c
.RI "#define \fBPEND_NLIST_NBLOCK_APP\fP   59"
.br
.ti -1c
.RI "#define \fBPEND_NLIST_NBLOCK_QUEUE\fP   60"
.br
.ti -1c
.RI "#define \fBPEND_NOTMATCH_NBLOCK_HOST\fP   61"
.br
.ti -1c
.RI "#define \fBPEND_NO_CANDIDATE_HOST\fP   62"
.br
.ti -1c
.RI "#define \fBPEND_MAX_JOB_DISPATCH\fP   63"
.br
.ti -1c
.RI "#define \fBPEND_RC_HOSTS_NOT_DEFINED\fP   64"
.br
.ti -1c
.RI "#define \fBPEND_RC_HOSTS_DOES_NOT_MATCH\fP   65"
.br
.ti -1c
.RI "#define \fBPEND_STAGE_STORAGE\fP   69"
.br
.ti -1c
.RI "#define \fBPEND_ADVRSV_OVERAGE\fP   70"
.br
.ti -1c
.RI "#define \fBPEND_ADVRSV_USER\fP   71"
.br
.ti -1c
.RI "#define \fBPEND_MAX_JOB_SCHEDULING_INTVL\fP   72"
.br
.ti -1c
.RI "#define \fBPEND_QUE_INACT\fP   301"
.br
.ti -1c
.RI "#define \fBPEND_QUE_WINDOW\fP   302"
.br
.ti -1c
.RI "#define \fBPEND_QUE_JOB_LIMIT\fP   303"
.br
.ti -1c
.RI "#define \fBPEND_QUE_USR_JLIMIT\fP   304"
.br
.ti -1c
.RI "#define \fBPEND_QUE_USR_PJLIMIT\fP   305"
.br
.ti -1c
.RI "#define \fBPEND_QUE_PRE_FAIL\fP   306"
.br
.ti -1c
.RI "#define \fBPEND_NQS_RETRY\fP   307"
.br
.ti -1c
.RI "#define \fBPEND_NQS_REASONS\fP   308"
.br
.ti -1c
.RI "#define \fBPEND_NQS_FUN_OFF\fP   309"
.br
.ti -1c
.RI "#define \fBPEND_SYS_NOT_READY\fP   310"
.br
.ti -1c
.RI "#define \fBPEND_SBD_JOB_REQUEUE\fP   311"
.br
.ti -1c
.RI "#define \fBPEND_JOB_SPREAD_TASK\fP   312"
.br
.ti -1c
.RI "#define \fBPEND_QUE_SPREAD_TASK\fP   313"
.br
.ti -1c
.RI "#define \fBPEND_QUE_PJOB_LIMIT\fP   314"
.br
.ti -1c
.RI "#define \fBPEND_QUE_WINDOW_WILL_CLOSE\fP   315"
.br
.ti -1c
.RI "#define \fBPEND_QUE_PROCLIMIT\fP   316"
.br
.ti -1c
.RI "#define \fBPEND_SBD_PLUGIN\fP   317"
.br
.ti -1c
.RI "#define \fBPEND_WAIT_SIGN_LEASE\fP   318"
.br
.ti -1c
.RI "#define \fBPEND_WAIT_SLOT_SHARE\fP   319"
.br
.ti -1c
.RI "#define \fBPEND_QUE_RMT_PERMISSION\fP   320"
.br
.ti -1c
.RI "#define \fBPEND_USER_JOB_LIMIT\fP   601"
.br
.ti -1c
.RI "#define \fBPEND_UGRP_JOB_LIMIT\fP   602"
.br
.ti -1c
.RI "#define \fBPEND_USER_PJOB_LIMIT\fP   603"
.br
.ti -1c
.RI "#define \fBPEND_UGRP_PJOB_LIMIT\fP   604"
.br
.ti -1c
.RI "#define \fBPEND_USER_RESUME\fP   605"
.br
.ti -1c
.RI "#define \fBPEND_USER_STOP\fP   607"
.br
.ti -1c
.RI "#define \fBPEND_NO_MAPPING\fP   608"
.br
.ti -1c
.RI "#define \fBPEND_RMT_PERMISSION\fP   609"
.br
.ti -1c
.RI "#define \fBPEND_ADMIN_STOP\fP   610"
.br
.ti -1c
.RI "#define \fBPEND_MLS_INVALID\fP   611"
.br
.ti -1c
.RI "#define \fBPEND_MLS_CLEARANCE\fP   612"
.br
.ti -1c
.RI "#define \fBPEND_MLS_RHOST\fP   613"
.br
.ti -1c
.RI "#define \fBPEND_MLS_DOMINATE\fP   614"
.br
.ti -1c
.RI "#define \fBPEND_MLS_FATAL\fP   615"
.br
.ti -1c
.RI "#define \fBPEND_INTERNAL_STOP\fP   616"
.br
.ti -1c
.RI "#define \fBPEND_USER_JOB_SLOT_LIMIT_RESTRICTION\fP   617"
.br
.ti -1c
.RI "#define \fBPEND_HOST_RES_REQ\fP   1001"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NONEXCLUSIVE\fP   1002"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JOB_SSUSP\fP   1003"
.br
.ti -1c
.RI "#define \fBPEND_HOST_PART_PRIO\fP   1004"
.br
.ti -1c
.RI "#define \fBPEND_SBD_GETPID\fP   1005"
.br
.ti -1c
.RI "#define \fBPEND_SBD_LOCK\fP   1006"
.br
.ti -1c
.RI "#define \fBPEND_SBD_ZOMBIE\fP   1007"
.br
.ti -1c
.RI "#define \fBPEND_SBD_ROOT\fP   1008"
.br
.ti -1c
.RI "#define \fBPEND_HOST_WIN_WILL_CLOSE\fP   1009"
.br
.ti -1c
.RI "#define \fBPEND_HOST_MISS_DEADLINE\fP   1010"
.br
.ti -1c
.RI "#define \fBPEND_FIRST_HOST_INELIGIBLE\fP   1011"
.br
.ti -1c
.RI "#define \fBPEND_HOST_EXCLUSIVE_RESERVE\fP   1012"
.br
.ti -1c
.RI "#define \fBPEND_FIRST_HOST_REUSE\fP   1013"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JOB_VM\fP   1014"
.br
.ti -1c
.RI "#define \fBPEND_HOSTFILE\fP   1015"
.br
.ti -1c
.RI "#define \fBPEND_HOST_DISABLED\fP   1301"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LOCKED\fP   1302"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LESS_SLOTS\fP   1303"
.br
.ti -1c
.RI "#define \fBPEND_HOST_WINDOW\fP   1304"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JOB_LIMIT\fP   1305"
.br
.ti -1c
.RI "#define \fBPEND_QUE_PROC_JLIMIT\fP   1306"
.br
.ti -1c
.RI "#define \fBPEND_QUE_HOST_JLIMIT\fP   1307"
.br
.ti -1c
.RI "#define \fBPEND_USER_PROC_JLIMIT\fP   1308"
.br
.ti -1c
.RI "#define \fBPEND_HOST_USR_JLIMIT\fP   1309"
.br
.ti -1c
.RI "#define \fBPEND_HOST_QUE_MEMB\fP   1310"
.br
.ti -1c
.RI "#define \fBPEND_HOST_USR_SPEC\fP   1311"
.br
.ti -1c
.RI "#define \fBPEND_HOST_PART_USER\fP   1312"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NO_USER\fP   1313"
.br
.ti -1c
.RI "#define \fBPEND_HOST_ACCPT_ONE\fP   1314"
.br
.ti -1c
.RI "#define \fBPEND_LOAD_UNAVAIL\fP   1315"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NO_LIM\fP   1316"
.br
.ti -1c
.RI "#define \fBPEND_HOST_UNLICENSED\fP   1317"
.br
.ti -1c
.RI "#define \fBPEND_HOST_QUE_RESREQ\fP   1318"
.br
.ti -1c
.RI "#define \fBPEND_HOST_SCHED_TYPE\fP   1319"
.br
.ti -1c
.RI "#define \fBPEND_JOB_NO_SPAN\fP   1320"
.br
.ti -1c
.RI "#define \fBPEND_QUE_NO_SPAN\fP   1321"
.br
.ti -1c
.RI "#define \fBPEND_HOST_EXCLUSIVE\fP   1322"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JS_DISABLED\fP   1323"
.br
.ti -1c
.RI "#define \fBPEND_UGRP_PROC_JLIMIT\fP   1324"
.br
.ti -1c
.RI "#define \fBPEND_BAD_HOST\fP   1325"
.br
.ti -1c
.RI "#define \fBPEND_QUEUE_HOST\fP   1326"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LOCKED_MASTER\fP   1327"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LESS_RSVSLOTS\fP   1328"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LESS_DURATION\fP   1329"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NO_RSVID\fP   1330"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LEASE_INACTIVE\fP   1331"
.br
.ti -1c
.RI "#define \fBPEND_HOST_ADRSV_ACTIVE\fP   1332"
.br
.ti -1c
.RI "#define \fBPEND_QUE_RSVID_NOMATCH\fP   1333"
.br
.ti -1c
.RI "#define \fBPEND_HOST_GENERAL\fP   1334"
.br
.ti -1c
.RI "#define \fBPEND_HOST_RSV\fP   1335"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NOT_CU\fP   1336"
.br
.ti -1c
.RI "#define \fBPEND_HOST_CU_EXCL\fP   1337"
.br
.ti -1c
.RI "#define \fBPEND_HOST_CU_OCCUPIED\fP   1338"
.br
.ti -1c
.RI "#define \fBPEND_HOST_USABLE_CU\fP   1339"
.br
.ti -1c
.RI "#define \fBPEND_JOB_FIRST_CU\fP   1340"
.br
.ti -1c
.RI "#define \fBPEND_HOST_CU_EXCL_RSV\fP   1341"
.br
.ti -1c
.RI "#define \fBPEND_JOB_CU_MAXCUS\fP   1342"
.br
.ti -1c
.RI "#define \fBPEND_JOB_CU_BALANCE\fP   1343"
.br
.ti -1c
.RI "#define \fBPEND_CU_TOPLIB_HOST\fP   1344"
.br
.ti -1c
.RI "#define \fBPEND_HOST_PREEXEC_FAIL\fP   1345"
.br
.ti -1c
.RI "#define \fBPEND_HOST_VNODE\fP   1346"
.br
.ti -1c
.RI "#define \fBPEND_JOB_HOST_LIMIT\fP   1347"
.br
.ti -1c
.RI "#define \fBPEND_DURATION_OTHERS\fP   1348"
.br
.ti -1c
.RI "#define \fBPEND_HOST_IN_CYCLE_TIME\fP   1349"
.br
.ti -1c
.RI "#define \fBPEND_HOST_REMOTE_DATA_REQ\fP   1350"
.br
.ti -1c
.RI "#define \fBPEND_HOST_DISCONNECTED\fP   1351"
.br
.ti -1c
.RI "#define \fBPEND_HOST_TEMPLATE_REP\fP   1352"
.br
.ti -1c
.RI "#define \fBPEND_HOST_HATTR_INVALID\fP   1353"
.br
.ti -1c
.RI "#define \fBPEND_SBD_UNREACH\fP   1601"
.br
.ti -1c
.RI "#define \fBPEND_SBD_JOB_QUOTA\fP   1602"
.br
.ti -1c
.RI "#define \fBPEND_JOB_START_FAIL\fP   1603"
.br
.ti -1c
.RI "#define \fBPEND_JOB_START_UNKNWN\fP   1604"
.br
.ti -1c
.RI "#define \fBPEND_SBD_NO_MEM\fP   1605"
.br
.ti -1c
.RI "#define \fBPEND_SBD_NO_PROCESS\fP   1606"
.br
.ti -1c
.RI "#define \fBPEND_SBD_SOCKETPAIR\fP   1607"
.br
.ti -1c
.RI "#define \fBPEND_SBD_JOB_ACCEPT\fP   1608"
.br
.ti -1c
.RI "#define \fBPEND_LEASE_JOB_REMOTE_DISPATCH\fP   1609"
.br
.ti -1c
.RI "#define \fBPEND_JOB_RESTART_FAIL\fP   1610"
.br
.ti -1c
.RI "#define \fBPEND_CHUNK_MAX_WAIT_TIME\fP   1611"
.br
.ti -1c
.RI "#define \fBPEND_SBD_WRITE_EVENT_FAIL\fP   1612"
.br
.ti -1c
.RI "#define \fBPEND_HOST_LOAD\fP   2001"
.br
.ti -1c
.RI "#define \fBPEND_HOST_QUE_RUSAGE\fP   2301"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JOB_RUSAGE\fP   2601"
.br
.ti -1c
.RI "#define \fBPEND_RMT_JOB_FORGOTTEN\fP   2901"
.br
.ti -1c
.RI "#define \fBPEND_RMT_IMPT_JOBBKLG\fP   2902"
.br
.ti -1c
.RI "#define \fBPEND_RMT_MAX_RSCHED_TIME\fP   2903"
.br
.ti -1c
.RI "#define \fBPEND_RMT_MAX_PREEXEC_RETRY\fP   2904"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_CLOSED\fP   2905"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_INACTIVE\fP   2906"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_CONGESTED\fP   2907"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_DISCONNECT\fP   2908"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_NOPERMISSION\fP   2909"
.br
.ti -1c
.RI "#define \fBPEND_RMT_BAD_TIME\fP   2910"
.br
.ti -1c
.RI "#define \fBPEND_RMT_PERMISSIONS\fP   2911"
.br
.ti -1c
.RI "#define \fBPEND_RMT_PROC_NUM\fP   2912"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_USE\fP   2913"
.br
.ti -1c
.RI "#define \fBPEND_RMT_NO_INTERACTIVE\fP   2914"
.br
.ti -1c
.RI "#define \fBPEND_RMT_ONLY_INTERACTIVE\fP   2915"
.br
.ti -1c
.RI "#define \fBPEND_RMT_PROC_LESS\fP   2916"
.br
.ti -1c
.RI "#define \fBPEND_RMT_OVER_LIMIT\fP   2917"
.br
.ti -1c
.RI "#define \fBPEND_RMT_BAD_RESREQ\fP   2918"
.br
.ti -1c
.RI "#define \fBPEND_RMT_CREATE_JOB\fP   2919"
.br
.ti -1c
.RI "#define \fBPEND_RMT_RERUN\fP   2920"
.br
.ti -1c
.RI "#define \fBPEND_RMT_EXIT_REQUEUE\fP   2921"
.br
.ti -1c
.RI "#define \fBPEND_RMT_REQUEUE\fP   2922"
.br
.ti -1c
.RI "#define \fBPEND_RMT_JOB_FORWARDING\fP   2923"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_INVALID\fP   2924"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_NO_EXCLUSIVE\fP   2925"
.br
.ti -1c
.RI "#define \fBPEND_RMT_UGROUP_MEMBER\fP   2926"
.br
.ti -1c
.RI "#define \fBPEND_RMT_INTERACTIVE_RERUN\fP   2927"
.br
.ti -1c
.RI "#define \fBPEND_RMT_JOB_START_FAIL\fP   2928"
.br
.ti -1c
.RI "#define \fBPEND_RMT_FORWARD_FAIL_UGROUP_MEMBER\fP   2930"
.br
.ti -1c
.RI "#define \fBPEND_RMT_HOST_NO_RSVID\fP   2931"
.br
.ti -1c
.RI "#define \fBPEND_RMT_APP_NULL\fP   2932"
.br
.ti -1c
.RI "#define \fBPEND_RMT_BAD_RUNLIMIT\fP   2933"
.br
.ti -1c
.RI "#define \fBPEND_RMT_OVER_QUEUE_LIMIT\fP   2934"
.br
.ti -1c
.RI "#define \fBPEND_RMT_WHEN_NO_SLOTS\fP   2935"
.br
.ti -1c
.RI "#define \fBPEND_RMT_ADJUST_ASKHOST\fP   2936"
.br
.ti -1c
.RI "#define \fBPEND_RMT_NO_VALID_ASKHOST\fP   2937"
.br
.ti -1c
.RI "#define \fBPEND_RMT_BRUN_FAILED\fP   2938"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_HOST\fP   2939"
.br
.ti -1c
.RI "#define \fBPEND_RMT_UNFORWARD\fP   2940"
.br
.ti -1c
.RI "#define \fBPEND_RMT_JOB_BOT\fP   2941"
.br
.ti -1c
.RI "#define \fBPEND_RMT_ASKED_RESOURCE\fP   2942"
.br
.ti -1c
.RI "#define \fBPEND_RMT_BAD_ASKED_CLUSTER\fP   2943"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_ASKED_CLUSTER\fP   2944"
.br
.ti -1c
.RI "#define \fBPEND_RMT_PROC_APP_QUE\fP   2945"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_DATA_REQ\fP   2946"
.br
.ti -1c
.RI "#define \fBPEND_RMT_QUEUE_STAGE_REQ\fP   2947"
.br
.ti -1c
.RI "#define \fBPEND_REMOTE_NOTSUPPORT_RLIMITS64\fP   2948"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_USER\fP   3201"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_QUEUE\fP   3501"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_PROJECT\fP   3801"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_CLUSTER\fP   4101"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_HOST\fP   4401"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_USER\fP   4701"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_QUEUE\fP   4702"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_PROJECT\fP   4703"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_CLUSTER\fP   4704"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_HOST\fP   4705"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_LIC_PROJECT\fP   4706"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOBS_APP\fP   4707"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOB_DISPATCH_USER\fP   4751"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_JOB_DISPATCH_QUEUE\fP   4752"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_FWDSLOTS_QUEUE\fP   4801"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_FWDSLOTS_USER\fP   4802"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_FWDSLOTS_PROJECT\fP   4803"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_FWDSLOTS_CLUSTER\fP   4804"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_FWDSLOTS_APP\fP   4805"
.br
.ti -1c
.RI "#define \fBPEND_RMS_PLUGIN_INTERNAL\fP   4900"
.br
.ti -1c
.RI "#define \fBPEND_RMS_PLUGIN_RLA_COMM\fP   4901"
.br
.ti -1c
.RI "#define \fBPEND_RMS_NOT_AVAILABLE\fP   4902"
.br
.ti -1c
.RI "#define \fBPEND_RMS_FAIL_TOPOLOGY\fP   4903"
.br
.ti -1c
.RI "#define \fBPEND_RMS_FAIL_ALLOC\fP   4904"
.br
.ti -1c
.RI "#define \fBPEND_RMS_SPECIAL_NO_PREEMPT_BACKFILL\fP   4905"
.br
.ti -1c
.RI "#define \fBPEND_RMS_SPECIAL_NO_RESERVE\fP   4906"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RLA_INTERNAL\fP   4907"
.br
.ti -1c
.RI "#define \fBPEND_RMS_NO_SLOTS_SPECIAL\fP   4908"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RLA_NO_SUCH_USER\fP   4909"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RLA_NO_SUCH_HOST\fP   4910"
.br
.ti -1c
.RI "#define \fBPEND_RMS_CHUNKJOB\fP   4911"
.br
.ti -1c
.RI "#define \fBPEND_RLA_PROTOMISMATCH\fP   4912"
.br
.ti -1c
.RI "#define \fBPEND_RMS_BAD_TOPOLOGY\fP   4913"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_MCONT\fP   4914"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_PTILE\fP   4915"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_NODES\fP   4916"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_BASE\fP   4917"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_RAILS\fP   4918"
.br
.ti -1c
.RI "#define \fBPEND_RMS_RESREQ_RAILMASK\fP   4919"
.br
.ti -1c
.RI "#define \fBPEND_MAUI_UNREACH\fP   5000"
.br
.ti -1c
.RI "#define \fBPEND_MAUI_FORWARD\fP   5001"
.br
.ti -1c
.RI "#define \fBPEND_MAUI_REASON\fP   5030"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_ATTACH\fP   5200"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_NOT_CPUSETHOST\fP   5201"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_INIT\fP   5202"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_TIME_OUT\fP   5203"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_FAIL_ALLOC\fP   5204"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_BAD_REQUEST\fP   5205"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_INTERNAL\fP   5206"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_SYSAPI_ERR\fP   5207"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_NOSUCH_NAME\fP   5208"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_JOB_EXIST\fP   5209"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_NO_MEMORY\fP   5210"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_INVALID_USER\fP   5211"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_PERM_DENY\fP   5212"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_UNREACH\fP   5213"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_TOPD_COMM_ERR\fP   5214"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_PLUGIN_INTERNAL\fP   5215"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_CHUNKJOB\fP   5216"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_CPULIST\fP   5217"
.br
.ti -1c
.RI "#define \fBPEND_CPUSET_MAXRADIUS\fP   5218"
.br
.ti -1c
.RI "#define \fBPEND_NODE_ALLOC_FAIL\fP   5300"
.br
.ti -1c
.RI "#define \fBPEND_RMSRID_UNAVAIL\fP   5400"
.br
.ti -1c
.RI "#define \fBPEND_NO_FREE_CPUS\fP   5450"
.br
.ti -1c
.RI "#define \fBPEND_TOPOLOGY_UNKNOWN\fP   5451"
.br
.ti -1c
.RI "#define \fBPEND_BAD_TOPOLOGY\fP   5452"
.br
.ti -1c
.RI "#define \fBPEND_RLA_COMM\fP   5453"
.br
.ti -1c
.RI "#define \fBPEND_RLA_NO_SUCH_USER\fP   5454"
.br
.ti -1c
.RI "#define \fBPEND_RLA_INTERNAL\fP   5455"
.br
.ti -1c
.RI "#define \fBPEND_RLA_NO_SUCH_HOST\fP   5456"
.br
.ti -1c
.RI "#define \fBPEND_RESREQ_TOOFEWSLOTS\fP   5457"
.br
.ti -1c
.RI "#define \fBPEND_PSET_PLUGIN_INTERNAL\fP   5500"
.br
.ti -1c
.RI "#define \fBPEND_PSET_RESREQ_PTILE\fP   5501"
.br
.ti -1c
.RI "#define \fBPEND_PSET_RESREQ_CELLS\fP   5502"
.br
.ti -1c
.RI "#define \fBPEND_PSET_CHUNKJOB\fP   5503"
.br
.ti -1c
.RI "#define \fBPEND_PSET_NOTSUPPORT\fP   5504"
.br
.ti -1c
.RI "#define \fBPEND_PSET_BIND_FAIL\fP   5505"
.br
.ti -1c
.RI "#define \fBPEND_PSET_RESREQ_CELLLIST\fP   5506"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_PLUGIN_INTERNAL\fP   5550"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_NODES\fP   5551"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_NODE_ATTR\fP   5552"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_EXCLUDE\fP   5553"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_NODELIST\fP   5554"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_CONTIGUOUS\fP   5555"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_ALLOC_UNAVAIL\fP   5556"
.br
.ti -1c
.RI "#define \fBPEND_SLURM_RESREQ_BAD_CONSTRAINT\fP   5557"
.br
.ti -1c
.RI "#define \fBPEND_CRAYX1_SSP\fP   5600"
.br
.ti -1c
.RI "#define \fBPEND_CRAYX1_MSP\fP   5601"
.br
.ti -1c
.RI "#define \fBPEND_CRAYX1_PASS_LIMIT\fP   5602"
.br
.ti -1c
.RI "#define \fBPEND_CRAYLINUX_ASSIGN_FAIL\fP   5650"
.br
.ti -1c
.RI "#define \fBPEND_CRAYLINUX_NODE_REUSE_INTERVAL\fP   5651"
.br
.ti -1c
.RI "#define \fBPEND_BLUEGENE_PLUGIN_INTERNAL\fP   5700"
.br
.ti -1c
.RI "#define \fBPEND_BLUEGENE_ALLOC_UNAVAIL\fP   5701"
.br
.ti -1c
.RI "#define \fBPEND_BLUEGENE_NOFREEMIDPLANES\fP   5702"
.br
.ti -1c
.RI "#define \fBPEND_BLUEGENE_NOFREEQUARTERS\fP   5703"
.br
.ti -1c
.RI "#define \fBPEND_BLUEGENE_NOFREENODECARDS\fP   5704"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_FIRSTHOSTUNAVAIL\fP   5705"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_MASTERSUSP\fP   5706"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_MASTER_SAME\fP   5707"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_SPAN_PTILE\fP   5708"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_SPAN_HOSTS\fP   5709"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_LEASE_HOST\fP   5710"
.br
.ti -1c
.RI "#define \fBPEND_RESIZE_POWER_SAVED_HOST\fP   5711"
.br
.ti -1c
.RI "#define \fBPEND_PS_PLUGIN_INTERNAL\fP   5750"
.br
.ti -1c
.RI "#define \fBPEND_PS_MBD_SYNC\fP   5751"
.br
.ti -1c
.RI "#define \fBPEND_COMPOUND_RESREQ_OLD_LEASE_HOST\fP   5800"
.br
.ti -1c
.RI "#define \fBPEND_COMPOUND_RESREQ_TOPLIB_HOST\fP   5801"
.br
.ti -1c
.RI "#define \fBPEND_ALTERNATIVE_RESREQ_OLD_LEASE_HOST\fP   5802"
.br
.ti -1c
.RI "#define \fBPEND_FWD_COMPOUND_RESREQ\fP   5803"
.br
.ti -1c
.RI "#define \fBPEND_FWD_ALTERNATIVE_RESREQ\fP   5804"
.br
.ti -1c
.RI "#define \fBPEND_ALTERNATIVE_RESREQ_TOPLIB_HOST\fP   5805"
.br
.ti -1c
.RI "#define \fBPEND_FWD_GLOBAL_SAME_NOT_SUPPORTED\fP   5806"
.br
.ti -1c
.RI "#define \fBPEND_BLOCK_RESREQ_OLD_LEASE_HOST\fP   5807"
.br
.ti -1c
.RI "#define \fBPEND_FWD_BLOCK_RESREQ_NOT_SUPPORTED\fP   5808"
.br
.ti -1c
.RI "#define \fBPEND_COMPOUND_RESREQ_USER_HOST_FILE\fP   5809"
.br
.ti -1c
.RI "#define \fBPEND_FWD_ALTERNATIVE_CU_NOT_SUPPORTED\fP   5810"
.br
.ti -1c
.RI "#define \fBPEND_CU_EXCL_BALANCE\fP   5812"
.br
.ti -1c
.RI "#define \fBPEND_MULTIPHASE_RESREQ_OLD_LEASE_HOST\fP   5900"
.br
.ti -1c
.RI "#define \fBPEND_AFFINITY_LACK_PU\fP   5901"
.br
.ti -1c
.RI "#define \fBPEND_AFFINITY_LACK_NUMA_MEMORY\fP   5902"
.br
.ti -1c
.RI "#define \fBPEND_NONE_AFFINITY_HOST\fP   5903"
.br
.ti -1c
.RI "#define \fBPEND_AFFINITY_LEASE_IN\fP   5904"
.br
.ti -1c
.RI "#define \fBPEND_NOT_REMOTE_AFFINITY_HOST\fP   5905"
.br
.ti -1c
.RI "#define \fBPEND_AFFINITY_BIND_DISABLED_HOST\fP   5906"
.br
.ti -1c
.RI "#define \fBPEND_NONE_GPU_HOST\fP   5907"
.br
.ti -1c
.RI "#define \fBPEND_GPU_LEASE_IN\fP   5908"
.br
.ti -1c
.RI "#define \fBPEND_QUEUE_SLOT_POOL_LIMIT\fP   5950"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_RSRC\fP   6000"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_SLOTS\fP   6300"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_HOSTS\fP   6301"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_SLOTS_PER_HOST\fP   6302"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_NONSLA\fP   6303"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_SLOTS_LIMIT\fP   6304"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_SLOTS_PKG\fP   6305"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_MEM_PKG\fP   6306"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_PKG\fP   6307"
.br
.ti -1c
.RI "#define \fBPEND_GUARANTEE_LOAN\fP   6308"
.br
.ti -1c
.RI "#define \fBPEND_CONS_GUAR_EXCEEDED\fP   6309"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_LIC_PROJECT\fP   6400"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_LIC_PROJECT_END\fP   6700"
.br
.ti -1c
.RI "#define \fBPEND_PREEMPT_DELAY\fP   6701"
.br
.ti -1c
.RI "#define \fBPEND_GLB_MIXED_MODE\fP   6702"
.br
.ti -1c
.RI "#define \fBPEND_EXTSCHED_REASON\fP   6703"
.br
.ti -1c
.RI "#define \fBPEND_PREEMPT_RESUME_DELAY\fP   6704"
.br
.ti -1c
.RI "#define \fBPEND_JOB_NO_FILE_SBDRESTART\fP   6705"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_MISSINFO\fP   6800"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_NO_PM_TEMPLATE\fP   6801"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_NO_MACHTYPE\fP   6802"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_NOT_ACJOB\fP   6803"
.br
.ti -1c
.RI "#define \fBPEND_AC_BAD_PROV_REQ\fP   6804"
.br
.ti -1c
.RI "#define \fBPEND_AC_PROV_REQ_FAIL\fP   6805"
.br
.ti -1c
.RI "#define \fBPEND_AC_LESS_MAXMEM\fP   6806"
.br
.ti -1c
.RI "#define \fBPEND_AC_VM_POWERINGOFF\fP   6807"
.br
.ti -1c
.RI "#define \fBPEND_AC_UNUSE_SLOTS\fP   6808"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NO_AC_PLUGIN\fP   6809"
.br
.ti -1c
.RI "#define \fBPEND_AC_ACJOB_PREEMPTED\fP   6810"
.br
.ti -1c
.RI "#define \fBPEND_AC_ACJOB_RESTORE_FAIL\fP   6811"
.br
.ti -1c
.RI "#define \fBPEND_AC_FAIL_CREATE_REQ\fP   6812"
.br
.ti -1c
.RI "#define \fBPEND_AC_RESTOREVM_NOT_SAME_RESGROUP\fP   6813"
.br
.ti -1c
.RI "#define \fBPEND_AC_RESTOREVM_NOT_ACHOST\fP   6814"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_NO_VM_TEMPLATE\fP   6815"
.br
.ti -1c
.RI "#define \fBPEND_AC_PM_INPROVISIONING\fP   6816"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_PM_TEMPLATE_NOMATCH\fP   6817"
.br
.ti -1c
.RI "#define \fBPEND_AC_PM_RESERVE_TEMPLATE\fP   6018"
.br
.ti -1c
.RI "#define \fBPEND_AC_NOT_READY\fP   6819"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_NOT_EMPTY\fP   6820"
.br
.ti -1c
.RI "#define \fBPEND_AC_LSF_NOT_READY\fP   6821"
.br
.ti -1c
.RI "#define \fBPEND_AC_TTL_NOTEXPIRED\fP   6822"
.br
.ti -1c
.RI "#define \fBPEND_AC_JOB_VM_NOSUSPENDED\fP   6823"
.br
.ti -1c
.RI "#define \fBPEND_AC_UNABLE_REPROVISIONING\fP   6824"
.br
.ti -1c
.RI "#define \fBPEND_AC_VMJOB_TOO_BIG_MEMSIZE\fP   6825"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_INELIGIBLE_FOR_REPROVISION\fP   6826"
.br
.ti -1c
.RI "#define \fBPEND_AC_TTL_NOTEXPIRED_ACHOST\fP   6827"
.br
.ti -1c
.RI "#define \fBPEND_AC_RMT_TEMPLATE_NOT_FOUND\fP   6828"
.br
.ti -1c
.RI "#define \fBPEND_AC_NOT_HYPERVISOR\fP   6829"
.br
.ti -1c
.RI "#define \fBPEND_AC_TOO_BIG_MEMSIZE_VM_ON_HV\fP   6830"
.br
.ti -1c
.RI "#define \fBPEND_AC_HOST_RESREQ_COMPOUND\fP   6831"
.br
.ti -1c
.RI "#define \fBPEND_AC_VMJOB_RESREQ_COMPOUND\fP   6832"
.br
.ti -1c
.RI "#define \fBPEND_AC_ACJOB_RESTART\fP   6833"
.br
.ti -1c
.RI "#define \fBPEND_AC_ACJOB_RESTART_FAIL\fP   6834"
.br
.ti -1c
.RI "#define \fBPEND_AC_USER_HOST_FILE\fP   6835"
.br
.ti -1c
.RI "#define \fBPEND_DS_NO_SPACE\fP   6901"
.br
.ti -1c
.RI "#define \fBPEND_DS_NO_ACCESS\fP   6902"
.br
.ti -1c
.RI "#define \fBPEND_DS_STORAGE_UNAVAIL\fP   6903"
.br
.ti -1c
.RI "#define \fBPEND_DS_STORAGE_CLOSE\fP   6904"
.br
.ti -1c
.RI "#define \fBPEND_DS_UNREG_DATASET\fP   6905"
.br
.ti -1c
.RI "#define \fBPEND_DS_NO_CLOSEST_STORAGE\fP   6906"
.br
.ti -1c
.RI "#define \fBPEND_DS_SYNTAX_ERROR\fP   6907"
.br
.ti -1c
.RI "#define \fBPEND_HOST_JOB_RUSAGE_THRESHOLD\fP   7101"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_WINDOW_LIMIT\fP   7401"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_JOB_DEDICATED\fP   7402"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_WINDOW_DEDICATED\fP   7403"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_WINDOW_FAILED\fP   7404"
.br
.ti -1c
.RI "#define \fBPEND_FWD_NETWORK_REQ\fP   7405"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_EXCEED_MAX_PROTOCOL_INSTANCE\fP   7406"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_CHKPNT\fP   7407"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_DISABLED\fP   7408"
.br
.ti -1c
.RI "#define \fBPEND_NETWORK_LEASE_IN_HOST\fP   7409"
.br
.ti -1c
.RI "#define \fBPEND_HOST_QUEUE_PRE_FAIL\fP   7430"
.br
.ti -1c
.RI "#define \fBPEND_HOST_APP_PRE_FAIL\fP   7431"
.br
.ti -1c
.RI "#define \fBPEND_START_MPS_DAEMON_FAIL\fP   7432"
.br
.ti -1c
.RI "#define \fBPEND_GPU_MODE_CHANGE_FAILED\fP   7433"
.br
.ti -1c
.RI "#define \fBPEND_GPU_CHECK_FAIL\fP   7434"
.br
.ti -1c
.RI "#define \fBPEND_GPU_HOST_NOT_SUPPORT\fP   7435"
.br
.ti -1c
.RI "#define \fBPEND_MANAGE_FREQUENCY_DISABLED\fP   7450"
.br
.ti -1c
.RI "#define \fBPEND_FREQUENCY_EXCLUSIVE\fP   7451"
.br
.ti -1c
.RI "#define \fBPEND_FREQUENCY_BY_CORE\fP   7452"
.br
.ti -1c
.RI "#define \fBPEND_AUTORESIZE_EAS_JOB\fP   7453"
.br
.ti -1c
.RI "#define \fBPEND_GENERATE_OR_AUTO_FREQ_DISABLE\fP   7454"
.br
.ti -1c
.RI "#define \fBPEND_GENERATE_OR_AUTO_FREQ_EXCLUSIVE\fP   7455"
.br
.ti -1c
.RI "#define \fBPEND_DATA_WAITING_FOR_STAGING\fP   7500"
.br
.ti -1c
.RI "#define \fBPEND_WAITING_FOR_PLANNED_ALLOCATION\fP   7501"
.br
.ti -1c
.RI "#define \fBPEND_JOB_EXCEEDED_FAILED_TRANSFER_JOB_LIMIT\fP   7502"
.br
.ti -1c
.RI "#define \fBPEND_HOST_NOT_IN_PLAN\fP   7503"
.br
.ti -1c
.RI "#define \fBPEND_EXTSCHED_HOST_FILE\fP   7600"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_APP\fP   7700"
.br
.ti -1c
.RI "#define \fBPEND_GENERAL_LIMIT_APP_END\fP   8000"
.br
.ti -1c
.RI "#define \fBPEND_CUSTOMER_MIN\fP   20001"
.br
.ti -1c
.RI "#define \fBPEND_CUSTOMER_MAX\fP   25000"
.br
.ti -1c
.RI "#define \fBPEND_MAX_REASONS\fP   25001"
.br
.in -1c
.SH "Detailed Description"
.PP 
Each entry in the table contains one of the following pending reasons. 
.SH "Define Documentation"
.PP 
.SS "#define PEND_JOB_REASON   0"
.PP
Virtual code; not a reason. 
.PP
.SS "#define PEND_JOB_NEW   1"
.PP
New job is waiting for scheduling. 
.PP
.SS "#define PEND_JOB_START_TIME   2"
.PP
Job has a specified start time. 
.PP
.SS "#define PEND_JOB_DEPEND   3"
.PP
Job dependency condition not satisfied. 
.PP
.SS "#define PEND_JOB_DEP_INVALID   4"
.PP
Dependency condition invalid or never satisfied. 
.PP
.SS "#define PEND_JOB_MIG   5"
.PP
Migrating job is waiting for rescheduling. 
.PP
.SS "#define PEND_JOB_PRE_EXEC   6"
.PP
Job's pre-exec command exited with non-zero status. 
.PP
.SS "#define PEND_JOB_NO_FILE   7"
.PP
Unable to access job file. 
.PP
.SS "#define PEND_JOB_ENV   8"
.PP
Unable to set job's environment variables. 
.PP
.SS "#define PEND_JOB_PATHS   9"
.PP
Unable to determine job's home/working directories. 
.PP
.SS "#define PEND_JOB_OPEN_FILES   10"
.PP
Unable to open job's I/O buffers. 
.PP
.SS "#define PEND_JOB_EXEC_INIT   11"
.PP
Job execution initialization failed. 
.PP
.SS "#define PEND_JOB_RESTART_FILE   12"
.PP
Unable to copy restarting job's checkpoint files. 
.PP
.SS "#define PEND_JOB_DELAY_SCHED   13"
.PP
The schedule of the job is postponed for a while. 
.PP
.SS "#define PEND_JOB_SWITCH   14"
.PP
Waiting for rescheduling after switching queue. 
.PP
.SS "#define PEND_JOB_DEP_REJECT   15"
.PP
Event is rejected by eeventd due to syntax error. 
.PP
.SS "#define PEND_JOB_JS_DISABLED   16"
.PP
JobScheduler feature is not enabled. 
.PP
.SS "#define PEND_JOB_NO_PASSWD   17"
.PP
Failed to get user password. 
.PP
.SS "#define PEND_JOB_LOGON_FAIL   18"
.PP
Failed to logon user with password. 
.PP
.SS "#define PEND_JOB_MODIFY   19"
.PP
Waiting for rescheduling after parameters have been changed. 
.PP
.SS "#define PEND_JOB_TIME_INVALID   20"
.PP
Time event is invalid. 
.PP
.SS "#define PEND_TIME_EXPIRED   21"
.PP
Job time event expired. 
.PP
.SS "#define PEND_JOB_REQUEUED   23"
.PP
Requeue the job for the next run. 
.PP
.SS "#define PEND_WAIT_NEXT   24"
.PP
Waiting for the next time event. 
.PP
.SS "#define PEND_JGRP_HOLD   25"
.PP
The parent group is held. 
.PP
.SS "#define PEND_JGRP_INACT   26"
.PP
The parent group is inactive. 
.PP
.SS "#define PEND_JGRP_WAIT   27"
.PP
Dependency conditions satisfied, waiting for scheduling. 
.PP
.SS "#define PEND_JOB_RCLUS_UNREACH   28"
.PP
Remote clusters are unreachable. 
.PP
.SS "#define PEND_JOB_QUE_REJECT   29"
.PP
SNDJOBS_TO queue rejected by remote cluster(s). 
.PP
.SS "#define PEND_JOB_RSCHED_START   30"
.PP
Waiting for remote scheduling session. 
.PP
.SS "#define PEND_JOB_RSCHED_ALLOC   31"
.PP
Waiting for allocation replies from remote cluster(s). 
.PP
.SS "#define PEND_JOB_FORWARDED   32"
.PP
Job forwarded to a remote cluster. 
.PP
.SS "#define PEND_JOB_RMT_ZOMBIE   33"
.PP
Job running remotely is in a zombie state. 
.PP
.SS "#define PEND_JOB_ENFUGRP   34"
.PP
Job's enforced user group share account not selected. 
.PP
.SS "#define PEND_SYS_UNABLE   35"
.PP
System is unable to schedule the job. 
.PP
.SS "#define PEND_JGRP_RELEASE   36"
.PP
The parent group has just been released. 
.PP
.SS "#define PEND_HAS_RUN   37"
.PP
Job has been run since the parent group was active. 
.PP
.SS "#define PEND_JOB_ARRAY_JLIMIT   38"
.PP
Job array has reached its running element limit. 
.PP
.SS "#define PEND_CHKPNT_DIR   39"
.PP
Checkpoint directory is invalid. 
.PP
.SS "#define PEND_CHUNK_FAIL   40"
.PP
The first job in the chunk failed (all other jobs in the chunk are set to PEND). 
.PP
.SS "#define PEND_JOB_SLA_MET   41"
.PP
Optimum number of running jobs for SLA has been reached, or the SLA is currently releasing the resource. 
.PP
.SS "#define PEND_JOB_APP_NOEXIST   42"
.PP
Specified application profile does not exist. 
.PP
.SS "#define PEND_APP_PROCLIMIT   43"
.PP
Job no longer satisfies application profile TASKLIMIT/JOB_SIZE_LIST configuration. 
.PP
.SS "#define PEND_EGO_NO_HOSTS   44"
.PP
No hosts are available from EGO. 
.PP
.SS "#define PEND_JGRP_JLIMIT   45"
.PP
The specified job group has reached its job limit. 
.PP
.SS "#define PEND_PREEXEC_LIMIT   46"
.PP
Job has reached its pre-execution retry limit. 
.PP
.SS "#define PEND_REQUEUE_LIMIT   47"
.PP
Job has reached its requeue limit. 
.PP
.SS "#define PEND_BAD_RESREQ   48"
.PP
Incorrect resource requirement syntax. 
.PP
.SS "#define PEND_RSV_INACTIVE   49"
.PP
Job is waiting for advance reservation to become active. 
.PP
.SS "#define PEND_WAITING_RESUME   50"
.PP
Waiting for user to resume job after correcting resource requirement syntax. 
.PP
.SS "#define PEND_SLOT_COMPOUND   51"
.PP
Job task request conflicts with total slots of compound resource requirement. 
.PP
.SS "#define PEND_SLOT_ALTERNATIVE   52"
.PP
Job task request conflicts with tasks of alternative resource requirement. 
.PP
.SS "#define PEND_FANOUT_FAIL   53"
.PP
Failed to send fan-out information to other SBDs. 
.PP
.SS "#define PEND_SLOT_LIST_JOB_LEVEL   54"
.PP
Not enough slots to satisfy the minimal job level task size list requirement in -nlist. 
.PP
.SS "#define PEND_JOB_SIZE_LIST_APP_LEVEL   55"
.PP
Job size is either a range or does not match a value in JOB_SIZE_LIST defined in application profile. 
.PP
.SS "#define PEND_JOB_SIZE_LIST_QUEUE_LEVEL   56"
.PP
Job size is either a range or does not match a value in JOB_SIZE_LIST defined in queue. 
.PP
.SS "#define PEND_NOTMATCH_NBLOCK   57"
.PP
Number of tasks requested by the job is not a multiple of the block size. 
.PP
.SS "#define PEND_NLIST_NBLOCK_JOB   58"
.PP
The task size list requirement in -nlist cannot be allocated as blocks. 
.PP
.SS "#define PEND_NLIST_NBLOCK_APP   59"
.PP
The task size list requirement in the application profile SLOT_SIZE_LIST cannot be allocated as blocks. 
.PP
.SS "#define PEND_NLIST_NBLOCK_QUEUE   60"
.PP
The task size list requirement in the queue-level SLOT_SIZE_LIST cannot be allocated as blocks. 
.PP
.SS "#define PEND_NOTMATCH_NBLOCK_HOST   61"
.PP
Cannot allocate specified block tasks on host. 
.PP
.SS "#define PEND_NO_CANDIDATE_HOST   62"
.PP
There are no suitable hosts for the job. 
.PP
.SS "#define PEND_MAX_JOB_DISPATCH   63"
.PP
The maximum job dispatch per session has been reached. 
.PP
.SS "#define PEND_RC_HOSTS_NOT_DEFINED   64"
.PP
the job does not run on the borrowed host because the RC_HOSTS value is not defined in the queue 
.PP
.SS "#define PEND_RC_HOSTS_DOES_NOT_MATCH   65"
.PP
the job does not run on the borrowed host because the RC_HOSTS value does not match 
.PP
.SS "#define PEND_STAGE_STORAGE   69"
.PP
Not enough stage storage resources available. 
.PP
.SS "#define PEND_ADVRSV_OVERAGE   70"
.PP
Job's run limit exceeds the end time of the advance reservantion. 
.PP
.SS "#define PEND_ADVRSV_USER   71"
.PP
User permissions denied for the advance reservation. 
.PP
.SS "#define PEND_MAX_JOB_SCHEDULING_INTVL   72"
.PP
The job reached the job scheduling interval threshold. 
.PP
.SS "#define PEND_QUE_INACT   301"
.PP
The queue is inactivated by the administrator. 
.PP
.SS "#define PEND_QUE_WINDOW   302"
.PP
The queue is inactivated by its time windows. 
.PP
.SS "#define PEND_QUE_JOB_LIMIT   303"
.PP
The queue has reached its job slot limit. 
.PP
.SS "#define PEND_QUE_USR_JLIMIT   304"
.PP
User has reached the per-user job slot limit of the queue. 
.PP
.SS "#define PEND_QUE_USR_PJLIMIT   305"
.PP
Not enough per-user job slots of the queue for the parallel job. 
.PP
.SS "#define PEND_QUE_PRE_FAIL   306"
.PP
The queue's pre-exec command exited with non-zero status. 
.PP
.SS "#define PEND_NQS_RETRY   307"
.PP
Job was not accepted by the NQS host. 
.PP
.SS "#define PEND_NQS_REASONS   308"
.PP
Unable to send the job to an NQS host. 
.PP
.SS "#define PEND_NQS_FUN_OFF   309"
.PP
Unable to contact NQS host. 
.PP
.SS "#define PEND_SYS_NOT_READY   310"
.PP
System is not ready for scheduling after reconfiguration. 
.PP
.SS "#define PEND_SBD_JOB_REQUEUE   311"
.PP
Requeued job is waiting for rescheduling. 
.PP
.SS "#define PEND_JOB_SPREAD_TASK   312"
.PP
Not enough hosts to meet the job's spanning requirement. 
.PP
.SS "#define PEND_QUE_SPREAD_TASK   313"
.PP
Not enough hosts to meet the queue's spanning requirement. 
.PP
.SS "#define PEND_QUE_PJOB_LIMIT   314"
.PP
The queue has not enough job slots for the parallel job. 
.PP
.SS "#define PEND_QUE_WINDOW_WILL_CLOSE   315"
.PP
Job will not finish before queue's run window is closed. 
.PP
.SS "#define PEND_QUE_PROCLIMIT   316"
.PP
Job no longer satisfies queue TASKLIMIT/JOB_SIZE_LIST configuration. 
.PP
.SS "#define PEND_SBD_PLUGIN   317"
.PP
Job requeued due to plug-in failure. 
.PP
.SS "#define PEND_WAIT_SIGN_LEASE   318"
.PP
Job is waiting for lease to be signed. 
.PP
.SS "#define PEND_WAIT_SLOT_SHARE   319"
.PP
Job is waiting for scheduling due to SLOT_SHARE configured in queue. 
.PP
.SS "#define PEND_QUE_RMT_PERMISSION   320"
.PP
The user does not have permission on the queue to forward jobs to remote hosts and clusters. 
.PP
.SS "#define PEND_USER_JOB_LIMIT   601"
.PP
The user has reached his/her job slot limit. 
.PP
.SS "#define PEND_UGRP_JOB_LIMIT   602"
.PP
One of the user's groups has reached its job slot limit. 
.PP
.SS "#define PEND_USER_PJOB_LIMIT   603"
.PP
The user has not enough job slots for the parallel job. 
.PP
.SS "#define PEND_UGRP_PJOB_LIMIT   604"
.PP
One of user's groups has not enough job slots for the parallel job. 
.PP
.SS "#define PEND_USER_RESUME   605"
.PP
Waiting for scheduling after resumed by administrator or user. 
.PP
.SS "#define PEND_USER_STOP   607"
.PP
Job was suspended by the user while pending. 
.PP
.SS "#define PEND_NO_MAPPING   608"
.PP
Unable to determine user account for execution. 
.PP
.SS "#define PEND_RMT_PERMISSION   609"
.PP
The user has no permission to run the job on remote host/cluster. 
.PP
.SS "#define PEND_ADMIN_STOP   610"
.PP
Job was suspended by LSF admin or root while pending. 
.PP
.SS "#define PEND_MLS_INVALID   611"
.PP
Requested label is not valid. 
.PP
.SS "#define PEND_MLS_CLEARANCE   612"
.PP
Requested label is above user allowed range. 
.PP
.SS "#define PEND_MLS_RHOST   613"
.PP
Requested label rejected by /etc/rhost.conf. 
.PP
.SS "#define PEND_MLS_DOMINATE   614"
.PP
Requested label doesn't dominate current label. 
.PP
.SS "#define PEND_MLS_FATAL   615"
.PP
Requested label problem. 
.PP
.SS "#define PEND_INTERNAL_STOP   616"
.PP
Job was suspended by the user while pending. 
.PP
.SS "#define PEND_USER_JOB_SLOT_LIMIT_RESTRICTION   617"
.PP
Job resource requirements are insufficient due to user slot limit. 
.PP
.SS "#define PEND_HOST_RES_REQ   1001"
.PP
Job's resource requirements not satisfied. 
.PP
.SS "#define PEND_HOST_NONEXCLUSIVE   1002"
.PP
Job's requirement for exclusive execution not satisfied. 
.PP
.SS "#define PEND_HOST_JOB_SSUSP   1003"
.PP
Higher or equal priority jobs suspended by host load. 
.PP
.SS "#define PEND_HOST_PART_PRIO   1004"
.PP
Job failed to compete with other jobs on host partition. 
.PP
.SS "#define PEND_SBD_GETPID   1005"
.PP
Unable to get the PID of the restarting job. 
.PP
.SS "#define PEND_SBD_LOCK   1006"
.PP
Unable to lock host for exclusively executing the job. 
.PP
.SS "#define PEND_SBD_ZOMBIE   1007"
.PP
Cleaning up zombie job. 
.PP
.SS "#define PEND_SBD_ROOT   1008"
.PP
Can't run jobs submitted by root. 
.PP
.SS "#define PEND_HOST_WIN_WILL_CLOSE   1009"
.PP
Job will not finish on the host before queue's run window is closed. 
.PP
.SS "#define PEND_HOST_MISS_DEADLINE   1010"
.PP
Job will not finish on the host before job's termination deadline. 
.PP
.SS "#define PEND_FIRST_HOST_INELIGIBLE   1011"
.PP
The specified first execution host is not eligible for this job at this time. 
.PP
.SS "#define PEND_HOST_EXCLUSIVE_RESERVE   1012"
.PP
An exclusive job has reserved the host. 
.PP
.SS "#define PEND_FIRST_HOST_REUSE   1013"
.PP
First execution candidate hosts cannot be used later in the job allocation. 
.PP
.SS "#define PEND_HOST_JOB_VM   1014"
.PP
Job virtual machine container host cannot be used for scheduling. 
.PP
.SS "#define PEND_HOSTFILE   1015"
.PP
Host(s) not included in user-specified host file. 
.PP
.SS "#define PEND_HOST_DISABLED   1301"
.PP
Closed by LSF administrator. 
.PP
.SS "#define PEND_HOST_LOCKED   1302"
.PP
Host is locked by LSF administrator. 
.PP
.SS "#define PEND_HOST_LESS_SLOTS   1303"
.PP
Not enough job slot(s). 
.PP
.SS "#define PEND_HOST_WINDOW   1304"
.PP
Dispatch windows closed. 
.PP
.SS "#define PEND_HOST_JOB_LIMIT   1305"
.PP
Job slot limit reached. 
.PP
.SS "#define PEND_QUE_PROC_JLIMIT   1306"
.PP
Queue's per-CPU job slot limit reached. 
.PP
.SS "#define PEND_QUE_HOST_JLIMIT   1307"
.PP
Queue's per-host job slot limit reached. 
.PP
.SS "#define PEND_USER_PROC_JLIMIT   1308"
.PP
User's per-CPU job slot limit reached. 
.PP
.SS "#define PEND_HOST_USR_JLIMIT   1309"
.PP
Host's per-user job slot limit reached. 
.PP
.SS "#define PEND_HOST_QUE_MEMB   1310"
.PP
Not usable to the queue. 
.PP
.SS "#define PEND_HOST_USR_SPEC   1311"
.PP
Not specified in job submission. 
.PP
.SS "#define PEND_HOST_PART_USER   1312"
.PP
User has no access to the host partition. 
.PP
.SS "#define PEND_HOST_NO_USER   1313"
.PP
There is no such user account. 
.PP
.SS "#define PEND_HOST_ACCPT_ONE   1314"
.PP
Just started a job recently. 
.PP
.SS "#define PEND_LOAD_UNAVAIL   1315"
.PP
Load information unavailable. 
.PP
.SS "#define PEND_HOST_NO_LIM   1316"
.PP
LIM is unreachable now. 
.PP
.SS "#define PEND_HOST_UNLICENSED   1317"
.PP
No LSF software licenses. 
.PP
.SS "#define PEND_HOST_QUE_RESREQ   1318"
.PP
Queue's resource requirements not satisfied. 
.PP
.SS "#define PEND_HOST_SCHED_TYPE   1319"
.PP
Not the same type as the submission host. 
.PP
.SS "#define PEND_JOB_NO_SPAN   1320"
.PP
Not enough processors to meet the job's spanning requirement. 
.PP
.SS "#define PEND_QUE_NO_SPAN   1321"
.PP
Not enough processors to meet the queue's spanning requirement. 
.PP
.SS "#define PEND_HOST_EXCLUSIVE   1322"
.PP
Running an exclusive job. 
.PP
.SS "#define PEND_HOST_JS_DISABLED   1323"
.PP
Not licensed to accept repetitive job. 
.PP
.SS "#define PEND_UGRP_PROC_JLIMIT   1324"
.PP
User group's per-CPU job slot limit reached. 
.PP
.SS "#define PEND_BAD_HOST   1325"
.PP
Bad host name, host group name or cluster name. 
.PP
.SS "#define PEND_QUEUE_HOST   1326"
.PP
Host or host group is not used by the queue. 
.PP
.SS "#define PEND_HOST_LOCKED_MASTER   1327"
.PP
Host is locked by master LIM. 
.PP
.SS "#define PEND_HOST_LESS_RSVSLOTS   1328"
.PP
Not enough reserved job slots at this time for specified reservation ID. 
.PP
.SS "#define PEND_HOST_LESS_DURATION   1329"
.PP
Not enough slots or resources for whole duration of the job. 
.PP
.SS "#define PEND_HOST_NO_RSVID   1330"
.PP
No hosts available for the specified reservation. 
.PP
.SS "#define PEND_HOST_LEASE_INACTIVE   1331"
.PP
The host is closed due to lease is inactive. 
.PP
.SS "#define PEND_HOST_ADRSV_ACTIVE   1332"
.PP
Not enough job slot(s) while advance reservation is active. 
.PP
.SS "#define PEND_QUE_RSVID_NOMATCH   1333"
.PP
This queue is not configured to send jobs to the cluster specified in the advance reservation. 
.PP
.SS "#define PEND_HOST_GENERAL   1334"
.PP
Individual host based reasons. 
.PP
.SS "#define PEND_HOST_RSV   1335"
.PP
Host does not belong to the specified advance reservation. 
.PP
.SS "#define PEND_HOST_NOT_CU   1336"
.PP
Host is not a member of a compute unit of the required type. 
.PP
.SS "#define PEND_HOST_CU_EXCL   1337"
.PP
Host is a member of a compute unit being used exclusively. 
.PP
.SS "#define PEND_HOST_CU_OCCUPIED   1338"
.PP
Host is in a compute unit not available for exclusive use. 
.PP
.SS "#define PEND_HOST_USABLE_CU   1339"
.PP
Host is a member of a compute unit that does not satisfy 'min_task_per_cu'. 
.PP
.SS "#define PEND_JOB_FIRST_CU   1340"
.PP
All first execution hosts are members of compute units that do not satisfy 'min_task_per_cu'. 
.PP
.SS "#define PEND_HOST_CU_EXCL_RSV   1341"
.PP
Host is a member of a compute unit with an exclusive reservation. 
.PP
.SS "#define PEND_JOB_CU_MAXCUS   1342"
.PP
Job's 'maxcus' requirement not satisfied. 
.PP
.SS "#define PEND_JOB_CU_BALANCE   1343"
.PP
Job's 'balance' requirement not satisfied. 
.PP
.SS "#define PEND_CU_TOPLIB_HOST   1344"
.PP
Hosts using LSF HPC system integrations do not support compute unit requirements. 
.PP
.SS "#define PEND_HOST_PREEXEC_FAIL   1345"
.PP
Excluded from rescheduling (PRE_EXEC unsuccessful). 
.PP
.SS "#define PEND_HOST_VNODE   1346"
.PP
Job cannot run on hosts with \\'vnode\\'. 
.PP
.SS "#define PEND_JOB_HOST_LIMIT   1347"
.PP
Queue level per job host limit reached. 
.PP
.SS "#define PEND_DURATION_OTHERS   1348"
.PP
Job's duration on host reduces slot or resource availability on other hosts selected for job. 
.PP
.SS "#define PEND_HOST_IN_CYCLE_TIME   1349"
.PP
Cycle time not expired. 
.PP
.SS "#define PEND_HOST_REMOTE_DATA_REQ   1350"
.PP
Host is not suitable for jobs with a data requirement. 
.PP
.SS "#define PEND_HOST_DISCONNECTED   1351"
.PP
The host cannot be scheduled because the sbatchd is not connected. 
.PP
.SS "#define PEND_HOST_TEMPLATE_REP   1352"
.PP
Template host only used for demand calculation. 
.PP
.SS "#define PEND_HOST_HATTR_INVALID   1353"
.PP
Job's mandatory attribute affinity requirements not satisfied. 
.PP
.SS "#define PEND_SBD_UNREACH   1601"
.PP
Unable to reach batch server. 
.PP
.SS "#define PEND_SBD_JOB_QUOTA   1602"
.PP
Number of jobs exceeds quota. 
.PP
.SS "#define PEND_JOB_START_FAIL   1603"
.PP
Failed in talking to server to start the job. 
.PP
.SS "#define PEND_JOB_START_UNKNWN   1604"
.PP
Failed in receiving the reply from server when starting the job. 
.PP
.SS "#define PEND_SBD_NO_MEM   1605"
.PP
Unable to allocate memory to run job. 
.PP
.SS "#define PEND_SBD_NO_PROCESS   1606"
.PP
Unable to fork process to run job. 
.PP
.SS "#define PEND_SBD_SOCKETPAIR   1607"
.PP
Unable to communicate with job process. 
.PP
.SS "#define PEND_SBD_JOB_ACCEPT   1608"
.PP
Batch server failed to accept job. 
.PP
.SS "#define PEND_LEASE_JOB_REMOTE_DISPATCH   1609"
.PP
Lease job remote dispatch failed. 
.PP
.SS "#define PEND_JOB_RESTART_FAIL   1610"
.PP
Failed to restart job from last checkpoint. 
.PP
.SS "#define PEND_CHUNK_MAX_WAIT_TIME   1611"
.PP
Job is in WAIT status for longer time than CHUNK_MAX_WAIT_TIME. 
.PP
.SS "#define PEND_SBD_WRITE_EVENT_FAIL   1612"
.PP
Batch server failed to write data into the events file. 
.PP
.SS "#define PEND_HOST_LOAD   2001"
.PP
Load threshold reached. 
.PP
.SS "#define PEND_HOST_QUE_RUSAGE   2301"
.PP
Queue's requirements for resource reservation not satisfied. 
.PP
.SS "#define PEND_HOST_JOB_RUSAGE   2601"
.PP
Job's requirements for resource reservation not satisfied. 
.PP
.SS "#define PEND_RMT_JOB_FORGOTTEN   2901"
.PP
Remote job not recognized by remote cluster, waiting for rescheduling. 
.PP
.SS "#define PEND_RMT_IMPT_JOBBKLG   2902"
.PP
Remote import limit reached, waiting for rescheduling. 
.PP
.SS "#define PEND_RMT_MAX_RSCHED_TIME   2903"
.PP
Remote schedule time reached, waiting for rescheduling. 
.PP
.SS "#define PEND_RMT_MAX_PREEXEC_RETRY   2904"
.PP
Remote pre-exec retry limit reached, waiting for rescheduling. 
.PP
.SS "#define PEND_RMT_QUEUE_CLOSED   2905"
.PP
Remote queue is closed. 
.PP
.SS "#define PEND_RMT_QUEUE_INACTIVE   2906"
.PP
Remote queue is inactive. 
.PP
.SS "#define PEND_RMT_QUEUE_CONGESTED   2907"
.PP
Remote queue is congested. 
.PP
.SS "#define PEND_RMT_QUEUE_DISCONNECT   2908"
.PP
Remote queue is disconnected. 
.PP
.SS "#define PEND_RMT_QUEUE_NOPERMISSION   2909"
.PP
Remote queue is not configured to accept jobs from this cluster. 
.PP
.SS "#define PEND_RMT_BAD_TIME   2910"
.PP
Job's termination time exceeds the job creation time on remote cluster. 
.PP
.SS "#define PEND_RMT_PERMISSIONS   2911"
.PP
Permission denied on the execution cluster. 
.PP
.SS "#define PEND_RMT_PROC_NUM   2912"
.PP
Required number of tasks for job cannot be satisfied by the remote cluster. 
.PP
.SS "#define PEND_RMT_QUEUE_USE   2913"
.PP
User is not defined in the fairshare policy of the remote queue. 
.PP
.SS "#define PEND_RMT_NO_INTERACTIVE   2914"
.PP
Remote queue is a non-interactive queue. 
.PP
.SS "#define PEND_RMT_ONLY_INTERACTIVE   2915"
.PP
Remote queue is an interactive-only queue. 
.PP
.SS "#define PEND_RMT_PROC_LESS   2916"
.PP
Required maximum number of tasks for job is less than the minimum number of tasks defined on the remote queue. 
.PP
.SS "#define PEND_RMT_OVER_LIMIT   2917"
.PP
Required resource limit for job exceeds that of the remote queue. 
.PP
.SS "#define PEND_RMT_BAD_RESREQ   2918"
.PP
Job's resource requirements do not match with those of the remote queue. 
.PP
.SS "#define PEND_RMT_CREATE_JOB   2919"
.PP
Job failed to be created on the remote cluster. 
.PP
.SS "#define PEND_RMT_RERUN   2920"
.PP
Job is requeued for rerun on the execution cluster. 
.PP
.SS "#define PEND_RMT_EXIT_REQUEUE   2921"
.PP
Job is requeued on the execution cluster due to exit value. 
.PP
.SS "#define PEND_RMT_REQUEUE   2922"
.PP
Job was killed and requeued on the execution cluster. 
.PP
.SS "#define PEND_RMT_JOB_FORWARDING   2923"
.PP
Job was forwarded to remote cluster. 
.PP
.SS "#define PEND_RMT_QUEUE_INVALID   2924"
.PP
Remote import queue defined for the job in lsb.queues is either not ready or not valid. 
.PP
.SS "#define PEND_RMT_QUEUE_NO_EXCLUSIVE   2925"
.PP
Remote queue is a non-exclusive queue. 
.PP
.SS "#define PEND_RMT_UGROUP_MEMBER   2926"
.PP
Job was rejected; submitter does not belong to the specified User Group in the remote cluster or the user group does not exist in the remote cluster. 
.PP
.SS "#define PEND_RMT_INTERACTIVE_RERUN   2927"
.PP
Remote queue is rerunnable: can not accept interactive jobs. 
.PP
.SS "#define PEND_RMT_JOB_START_FAIL   2928"
.PP
Remote cluster failed in talking to server to start the job. 
.PP
.SS "#define PEND_RMT_FORWARD_FAIL_UGROUP_MEMBER   2930"
.PP
Job was rejected; submitter does not belong to the specified User Group in the remote cluster or the user group does not exist in the remote cluster. 
.PP
.SS "#define PEND_RMT_HOST_NO_RSVID   2931"
.PP
Specified remote reservation has expired or has been deleted. 
.PP
.SS "#define PEND_RMT_APP_NULL   2932"
.PP
Application profile could not be found in the remote cluster. 
.PP
.SS "#define PEND_RMT_BAD_RUNLIMIT   2933"
.PP
Required RUNLIMIT for job exceeds RUNTIME * JOB_RUNLIMIT_RATIO of the remote cluste. 
.PP
.SS "#define PEND_RMT_OVER_QUEUE_LIMIT   2934"
.PP
Required RUNTIME for job exceeds the hard runtime limit in the remote queue. 
.PP
.SS "#define PEND_RMT_WHEN_NO_SLOTS   2935"
.PP
No slots are available among remote queues. 
.PP
.SS "#define PEND_RMT_ADJUST_ASKHOST   2936"
.PP
The job asked host was moved. 
.PP
.SS "#define PEND_RMT_NO_VALID_ASKHOST   2937"
.PP
No valid host in job asked hosts. 
.PP
.SS "#define PEND_RMT_BRUN_FAILED   2938"
.PP
Brun failed; job pending. 
.PP
.SS "#define PEND_RMT_QUEUE_HOST   2939"
.PP
Host or host group is not used by remote queue. 
.PP
.SS "#define PEND_RMT_UNFORWARD   2940"
.PP
Job has returned from remote cluster. 
.PP
.SS "#define PEND_RMT_JOB_BOT   2941"
.PP
Job has returned due to a remote bbot request. 
.PP
.SS "#define PEND_RMT_ASKED_RESOURCE   2942"
.PP
Requested clusters do not satisfy job requirement. 
.PP
.SS "#define PEND_RMT_BAD_ASKED_CLUSTER   2943"
.PP
Requested cluster name is not valid. 
.PP
.SS "#define PEND_RMT_QUEUE_ASKED_CLUSTER   2944"
.PP
Requested cluster is not defined in the queue for the forwarding clusters. 
.PP
.SS "#define PEND_RMT_PROC_APP_QUE   2945"
.PP
Remote application profile TASKLIMIT/JOB_SIZE_LIST rejected by the queue. 
.PP
.SS "#define PEND_RMT_QUEUE_DATA_REQ   2946"
.PP
Remote import queue not suitable for job with a data requirement. 
.PP
.SS "#define PEND_RMT_QUEUE_STAGE_REQ   2947"
.PP
Remote import queue not suitable for job with stage requirement. 
.PP
.SS "#define PEND_REMOTE_NOTSUPPORT_RLIMITS64   2948"
.PP
Remote cluster does not support 64-bit rlimits. 
.PP
.SS "#define PEND_GENERAL_LIMIT_USER   3201"
.PP
Resource limit defined on user or user group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_QUEUE   3501"
.PP
Resource limit defined on queue has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_PROJECT   3801"
.PP
Resource limit defined on project has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_CLUSTER   4101"
.PP
Resource limit defined cluster-wide has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_HOST   4401"
.PP
Resource limit defined on host(s) and/or host group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_USER   4701"
.PP
JOBS limit defined for the user or user group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_QUEUE   4702"
.PP
JOBS limit defined for the queue has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_PROJECT   4703"
.PP
JOBS limit defined for the project has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_CLUSTER   4704"
.PP
JOBS limit defined cluster-wide has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_HOST   4705"
.PP
JOBS limit defined on host or host group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_LIC_PROJECT   4706"
.PP
JOBS limit defined for the license project has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOBS_APP   4707"
.PP
JOBS limit defined for the application has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOB_DISPATCH_USER   4751"
.PP
JOB_DISPATCH_LIMIT defined for the user or user group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_JOB_DISPATCH_QUEUE   4752"
.PP
JOB_DISPATCH_LIMIT defined for the queue has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_FWDSLOTS_QUEUE   4801"
.PP
FWD_TASKS limit defined for the queue has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_FWDSLOTS_USER   4802"
.PP
FWD_TASKS limit defined for the user or user group has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_FWDSLOTS_PROJECT   4803"
.PP
FWD_TASKS limit defined for the project has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_FWDSLOTS_CLUSTER   4804"
.PP
FWD_TASKS limit defined for remote cluster has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_FWDSLOTS_APP   4805"
.PP
FWD_TASKS limit defined for the application has been reached. 
.PP
.SS "#define PEND_RMS_PLUGIN_INTERNAL   4900"
.PP
RMS scheduler plugin internal error. 
.PP
.SS "#define PEND_RMS_PLUGIN_RLA_COMM   4901"
.PP
RLA communication failure. 
.PP
.SS "#define PEND_RMS_NOT_AVAILABLE   4902"
.PP
RMS is not available. 
.PP
.SS "#define PEND_RMS_FAIL_TOPOLOGY   4903"
.PP
Cannot satisfy the topology requirement. 
.PP
.SS "#define PEND_RMS_FAIL_ALLOC   4904"
.PP
Cannot allocate an RMS resource. 
.PP
.SS "#define PEND_RMS_SPECIAL_NO_PREEMPT_BACKFILL   4905"
.PP
RMS job with special topology requirements cannot be preemptive or backfill job. 
.PP
.SS "#define PEND_RMS_SPECIAL_NO_RESERVE   4906"
.PP
RMS job with special topology requirements cannot reserve slots. 
.PP
.SS "#define PEND_RMS_RLA_INTERNAL   4907"
.PP
RLA internal error. 
.PP
.SS "#define PEND_RMS_NO_SLOTS_SPECIAL   4908"
.PP
Not enough slots for job. 
.PP
Job with RMS topology requirements cannot reserve slots, be preemptive, or be a backfill job 
.SS "#define PEND_RMS_RLA_NO_SUCH_USER   4909"
.PP
User account does not exist on the execution host. 
.PP
.SS "#define PEND_RMS_RLA_NO_SUCH_HOST   4910"
.PP
Unknown host and/or partition unavailable. 
.PP
.SS "#define PEND_RMS_CHUNKJOB   4911"
.PP
Cannot schedule chunk jobs to RMS hosts. 
.PP
.SS "#define PEND_RLA_PROTOMISMATCH   4912"
.PP
RLA protocol mismatch. 
.PP
.SS "#define PEND_RMS_BAD_TOPOLOGY   4913"
.PP
Contradictory topology requirements specified. 
.PP
.SS "#define PEND_RMS_RESREQ_MCONT   4914"
.PP
Not enough slots to satisfy manditory contiguous requirement. 
.PP
.SS "#define PEND_RMS_RESREQ_PTILE   4915"
.PP
Not enough slots to satisfy RMS ptile requirement. 
.PP
.SS "#define PEND_RMS_RESREQ_NODES   4916"
.PP
Not enough slots to satisfy RMS nodes requirement. 
.PP
.SS "#define PEND_RMS_RESREQ_BASE   4917"
.PP
Cannot satisfy RMS base node requirement. 
.PP
.SS "#define PEND_RMS_RESREQ_RAILS   4918"
.PP
Cannot satisfy RMS rails requirement. 
.PP
.SS "#define PEND_RMS_RESREQ_RAILMASK   4919"
.PP
Cannot satisfy RMS railmask requirement. 
.PP
.SS "#define PEND_MAUI_UNREACH   5000"
.PP
Unable to communicate with external Maui scheduler. 
.PP
.SS "#define PEND_MAUI_FORWARD   5001"
.PP
Job is pending at external Maui scheduler. 
.PP
.SS "#define PEND_MAUI_REASON   5030"
.PP
External Maui scheduler sets detail reason:. 
.PP
.SS "#define PEND_CPUSET_ATTACH   5200"
.PP
CPUSET attach failed. 
.PP
Job requeued 
.SS "#define PEND_CPUSET_NOT_CPUSETHOST   5201"
.PP
Not a cpuset host. 
.PP
.SS "#define PEND_CPUSET_TOPD_INIT   5202"
.PP
Topd initialization failed. 
.PP
.SS "#define PEND_CPUSET_TOPD_TIME_OUT   5203"
.PP
Topd communication timeout. 
.PP
.SS "#define PEND_CPUSET_TOPD_FAIL_ALLOC   5204"
.PP
Cannot satisfy the cpuset allocation requirement. 
.PP
.SS "#define PEND_CPUSET_TOPD_BAD_REQUEST   5205"
.PP
Bad cpuset allocation request. 
.PP
.SS "#define PEND_CPUSET_TOPD_INTERNAL   5206"
.PP
Topd internal error. 
.PP
.SS "#define PEND_CPUSET_TOPD_SYSAPI_ERR   5207"
.PP
Cpuset system API failure. 
.PP
.SS "#define PEND_CPUSET_TOPD_NOSUCH_NAME   5208"
.PP
Specified static cpuset does not exist on the host. 
.PP
.SS "#define PEND_CPUSET_TOPD_JOB_EXIST   5209"
.PP
Cpuset is already allocated for this job. 
.PP
.SS "#define PEND_CPUSET_TOPD_NO_MEMORY   5210"
.PP
Topd malloc failure. 
.PP
.SS "#define PEND_CPUSET_TOPD_INVALID_USER   5211"
.PP
User account does not exist on the cpuset host. 
.PP
.SS "#define PEND_CPUSET_TOPD_PERM_DENY   5212"
.PP
User does not have permission to run job within cpuset. 
.PP
.SS "#define PEND_CPUSET_TOPD_UNREACH   5213"
.PP
Topd is not available. 
.PP
.SS "#define PEND_CPUSET_TOPD_COMM_ERR   5214"
.PP
Topd communication failure. 
.PP
.SS "#define PEND_CPUSET_PLUGIN_INTERNAL   5215"
.PP
CPUSET Scheduler Plugin internal error. 
.PP
.SS "#define PEND_CPUSET_CHUNKJOB   5216"
.PP
Cannot schedule chunk jobs to cpuset hosts. 
.PP
.SS "#define PEND_CPUSET_CPULIST   5217"
.PP
Cannot satisfy CPUSET CPU_LIST requirement. 
.PP
.SS "#define PEND_CPUSET_MAXRADIUS   5218"
.PP
Cannot satisfy CPUSET MAX_RADIUS requirement. 
.PP
.SS "#define PEND_NODE_ALLOC_FAIL   5300"
.PP
Node allocation failed. 
.PP
.SS "#define PEND_RMSRID_UNAVAIL   5400"
.PP
RMS resource is not available. 
.PP
.SS "#define PEND_NO_FREE_CPUS   5450"
.PP
Not enough free cpus to satisfy job requirements. 
.PP
.SS "#define PEND_TOPOLOGY_UNKNOWN   5451"
.PP
Topology unknown or recently changed. 
.PP
.SS "#define PEND_BAD_TOPOLOGY   5452"
.PP
Contradictory topology requirement specified. 
.PP
.SS "#define PEND_RLA_COMM   5453"
.PP
RLA communications failure. 
.PP
.SS "#define PEND_RLA_NO_SUCH_USER   5454"
.PP
User account does not exist on execution host. 
.PP
.SS "#define PEND_RLA_INTERNAL   5455"
.PP
RLA internal error. 
.PP
.SS "#define PEND_RLA_NO_SUCH_HOST   5456"
.PP
Unknown host and/or partition unavailable. 
.PP
.SS "#define PEND_RESREQ_TOOFEWSLOTS   5457"
.PP
Too few slots for specified topology requirement. 
.PP
.SS "#define PEND_PSET_PLUGIN_INTERNAL   5500"
.PP
PSET scheduler plugin internal error. 
.PP
.SS "#define PEND_PSET_RESREQ_PTILE   5501"
.PP
Cannot satisfy PSET ptile requirement. 
.PP
.SS "#define PEND_PSET_RESREQ_CELLS   5502"
.PP
Cannot satisfy PSET cells requirement. 
.PP
.SS "#define PEND_PSET_CHUNKJOB   5503"
.PP
Cannot schedule chunk jobs to PSET hosts. 
.PP
.SS "#define PEND_PSET_NOTSUPPORT   5504"
.PP
Host does not support processor set functionality. 
.PP
.SS "#define PEND_PSET_BIND_FAIL   5505"
.PP
PSET bind failed. 
.PP
Job requeued 
.SS "#define PEND_PSET_RESREQ_CELLLIST   5506"
.PP
Cannot satisfy PSET CELL_LIST requirement. 
.PP
.SS "#define PEND_SLURM_PLUGIN_INTERNAL   5550"
.PP
SLURM scheduler plugin internal error. 
.PP
.SS "#define PEND_SLURM_RESREQ_NODES   5551"
.PP
Not enough resource to satisfy SLURM nodes requirment. 
.PP
.SS "#define PEND_SLURM_RESREQ_NODE_ATTR   5552"
.PP
Not enough resource to satisfy SLURM node attributes requirment. 
.PP
.SS "#define PEND_SLURM_RESREQ_EXCLUDE   5553"
.PP
Not enough resource to satisfy SLURM exclude requirment. 
.PP
.SS "#define PEND_SLURM_RESREQ_NODELIST   5554"
.PP
Not enough resource to satisfy SLURM nodelist requirment. 
.PP
.SS "#define PEND_SLURM_RESREQ_CONTIGUOUS   5555"
.PP
Not enough resource to satisfy SLURM contiguous requirment. 
.PP
.SS "#define PEND_SLURM_ALLOC_UNAVAIL   5556"
.PP
SLURM allocation is not available. 
.PP
Job requeued 
.SS "#define PEND_SLURM_RESREQ_BAD_CONSTRAINT   5557"
.PP
Invalid grammar in SLURM constraints option, job will never run. 
.PP
.SS "#define PEND_CRAYX1_SSP   5600"
.PP
Not enough SSPs for job. 
.PP
.SS "#define PEND_CRAYX1_MSP   5601"
.PP
Not enough MSPs for job. 
.PP
.SS "#define PEND_CRAYX1_PASS_LIMIT   5602"
.PP
Unable to pass job limit information to psched. 
.PP
.SS "#define PEND_CRAYLINUX_ASSIGN_FAIL   5650"
.PP
Cannot create/confirm a reservation by apbasil/catnip. 
.PP
.SS "#define PEND_CRAYLINUX_NODE_REUSE_INTERVAL   5651"
.PP
Recently released Cray compute node cannot be re-used at this moment. 
.PP
.SS "#define PEND_BLUEGENE_PLUGIN_INTERNAL   5700"
.PP
BG/L: Scheduler plug-in internal error. 
.PP
.SS "#define PEND_BLUEGENE_ALLOC_UNAVAIL   5701"
.PP
BG/L: Allocation is not available. 
.PP
Job requeued 
.SS "#define PEND_BLUEGENE_NOFREEMIDPLANES   5702"
.PP
BG/L: No free base partitions available for a full block allocation. 
.PP
.SS "#define PEND_BLUEGENE_NOFREEQUARTERS   5703"
.PP
BG/L: No free quarters available for a small block allocation. 
.PP
.SS "#define PEND_BLUEGENE_NOFREENODECARDS   5704"
.PP
BG/L: No free node cards available for a small block allocation. 
.PP
.SS "#define PEND_RESIZE_FIRSTHOSTUNAVAIL   5705"
.PP
Job's first execution host is unavailable. 
.PP
.SS "#define PEND_RESIZE_MASTERSUSP   5706"
.PP
The job is not in the RUN state. 
.PP
.SS "#define PEND_RESIZE_MASTER_SAME   5707"
.PP
Host does not satisfy job's 'same' requirement. 
.PP
.SS "#define PEND_RESIZE_SPAN_PTILE   5708"
.PP
Job's 'span' requirement prevents allocating for additional tasks. 
.PP
.SS "#define PEND_RESIZE_SPAN_HOSTS   5709"
.PP
Job can only get slots on the first execution host due to 'span' requirement. 
.PP
.SS "#define PEND_RESIZE_LEASE_HOST   5710"
.PP
Additional tasks can only be placed on local hosts. 
.PP
.SS "#define PEND_RESIZE_POWER_SAVED_HOST   5711"
.PP
Additional slots can not be allocated on power saved hosts. 
.PP
.SS "#define PEND_PS_PLUGIN_INTERNAL   5750"
.PP
Host does not have enough slots for this SLA job. 
.PP
.SS "#define PEND_PS_MBD_SYNC   5751"
.PP
EGO SLA: Failed to synchronize resource with MBD. 
.PP
.SS "#define PEND_COMPOUND_RESREQ_OLD_LEASE_HOST   5800"
.PP
MC lease hosts running LSF 7 Update 4 or earlier do not satisfy compound resource requirements. 
.PP
.SS "#define PEND_COMPOUND_RESREQ_TOPLIB_HOST   5801"
.PP
Hosts using LSF HPC system integrations do not support compound resource requirements. 
.PP
.SS "#define PEND_ALTERNATIVE_RESREQ_OLD_LEASE_HOST   5802"
.PP
MC lease hosts running LSF versions prior to 9.1 do not satisfy alternative resource requirements. 
.PP
.SS "#define PEND_FWD_COMPOUND_RESREQ   5803"
.PP
Remote MC queues for clusters running LSF versions prior to 7, update 5, do not satisfy compound resource requirements. 
.PP
.SS "#define PEND_FWD_ALTERNATIVE_RESREQ   5804"
.PP
Remote MC queues for clusters running LSF versions prior to 9.1 do not satisfy alternative resource requirements. 
.PP
.SS "#define PEND_ALTERNATIVE_RESREQ_TOPLIB_HOST   5805"
.PP
Hosts using LSF HPC system integrations do not support alternative resource requirements. 
.PP
.SS "#define PEND_FWD_GLOBAL_SAME_NOT_SUPPORTED   5806"
.PP
Remote MC queues for clusters running LSF versions prior to 9.1.1 do not satisfy compound or alternative resource requirements with global same[] sections. 
.PP
.SS "#define PEND_BLOCK_RESREQ_OLD_LEASE_HOST   5807"
.PP
MultiCluster lease hosts running LSF versions prior to 9.1.2 do not support block in the resource requirements. 
.PP
.SS "#define PEND_FWD_BLOCK_RESREQ_NOT_SUPPORTED   5808"
.PP
Remote MultiCluster queues for a cluster running LSF versions prior to 9.1.2 do not support block in the resource requirements. 
.PP
.SS "#define PEND_COMPOUND_RESREQ_USER_HOST_FILE   5809"
.PP
User-specified host file cannot be combined with compound resource requirements. 
.PP
.SS "#define PEND_FWD_ALTERNATIVE_CU_NOT_SUPPORTED   5810"
.PP
Remote MC queues for clusters running LSF versions prior to 10.1 do not satisfy alternative resource requirements using the cu[] feature. 
.PP
.SS "#define PEND_CU_EXCL_BALANCE   5812"
.PP
Compound or alternative resource requirements do not support compute unit specified with excl or balance. 
.PP
.SS "#define PEND_MULTIPHASE_RESREQ_OLD_LEASE_HOST   5900"
.PP
MultiCluster leased hosts running LSF Version 7 Update 5 or earlier do not satisfy multiple phase resource reservation requirements. 
.PP
.SS "#define PEND_AFFINITY_LACK_PU   5901"
.PP
Affinity resource requirement cannot be met because there are not enough processor units to satisfy the job affinity request. 
.PP
.SS "#define PEND_AFFINITY_LACK_NUMA_MEMORY   5902"
.PP
Affinity resource requirement cannot be met because there is not enough NUMA memory. 
.PP
.SS "#define PEND_NONE_AFFINITY_HOST   5903"
.PP
The specified hosts do not have the required affinity processor unit resources configured. 
.PP
.SS "#define PEND_AFFINITY_LEASE_IN   5904"
.PP
Affinity is not supported on leased-in hosts. 
.PP
.SS "#define PEND_NOT_REMOTE_AFFINITY_HOST   5905"
.PP
The job with affinity resource requirement cannot be forwarded because there are no affinity hosts in remote cluster. 
.PP
.SS "#define PEND_AFFINITY_BIND_DISABLED_HOST   5906"
.PP
Affinity binding is not enabled on the host. 
.PP
.SS "#define PEND_NONE_GPU_HOST   5907"
.PP
The specified hosts do not have the required gpu. 
.PP
.SS "#define PEND_GPU_LEASE_IN   5908"
.PP
Gpu is not supported on leased-in hosts. 
.PP
.SS "#define PEND_QUEUE_SLOT_POOL_LIMIT   5950"
.PP
Queue has reached job slot limit of slot pool. 
.PP
.SS "#define PEND_GUARANTEE_RSRC   6000"
.PP
Resource (s) reserved for SLA guarantees, or not enough resources available. 
.PP
.SS "#define PEND_GUARANTEE_SLOTS   6300"
.PP
Slots are reserved for guarantees. 
.PP
.SS "#define PEND_GUARANTEE_HOSTS   6301"
.PP
Host is reserved to honor SLA guarantees. 
.PP
.SS "#define PEND_GUARANTEE_SLOTS_PER_HOST   6302"
.PP
Per-host slot limit is reached for host in guaranteed slot pool. 
.PP
.SS "#define PEND_GUARANTEE_NONSLA   6303"
.PP
Remaining slots on host are reserved for SLA guarantees. 
.PP
.SS "#define PEND_GUARANTEE_SLOTS_LIMIT   6304"
.PP
Per-host slot limit on host(s) within guaranteed resource pool has been reached. 
.PP
.SS "#define PEND_GUARANTEE_SLOTS_PKG   6305"
.PP
Slots reserved for package guarantees. 
.PP
.SS "#define PEND_GUARANTEE_MEM_PKG   6306"
.PP
Memory reserved for package guarantees. 
.PP
.SS "#define PEND_GUARANTEE_PKG   6307"
.PP
Insufficient free packages on host. 
.PP
.SS "#define PEND_GUARANTEE_LOAN   6308"
.PP
Ignore non-pool hosts during loan scheduling. 
.PP
.SS "#define PEND_CONS_GUAR_EXCEEDED   6309"
.PP
Consumer has exceeded its guaranteed resources. 
.PP
.SS "#define PEND_GENERAL_LIMIT_LIC_PROJECT   6400"
.PP
Resource limit defined on license project has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_LIC_PROJECT_END   6700"
.PP
place holder for limit reason for license project 
.PP
.SS "#define PEND_PREEMPT_DELAY   6701"
.PP
The preemptive job is allowing a grace period before preemption. 
.PP
.SS "#define PEND_GLB_MIXED_MODE   6702"
.PP
Job requests both project mode and cluster mode License Scheduler resources. 
.PP
.SS "#define PEND_EXTSCHED_REASON   6703"
.PP
External scheduler reason:. 
.PP
.SS "#define PEND_PREEMPT_RESUME_DELAY   6704"
.PP
Resume blocked while preemption occurs for a pending job. 
.PP

.SS "#define PEND_JOB_NO_FILE_SBDRESTART   6705"
.PP
Unable to access jobfile due to socket error. 
.PP
.SS "#define PEND_AC_HOST_MISSINFO   6800"
.PP
Dynamic Cluster host cannot be used for scheduling due to missing information. 
.PP
.SS "#define PEND_AC_HOST_NO_PM_TEMPLATE   6801"
.PP
Dynamic Cluster host cannot provide the job-required physical machine template. 
.PP
.SS "#define PEND_AC_HOST_NO_MACHTYPE   6802"
.PP
Dynamic Cluster host cannot provide the job-required machine type. 
.PP
.SS "#define PEND_AC_HOST_NOT_ACJOB   6803"
.PP
Cannot schedule the job on the Dynamic Cluster host because there is no Dynamic Cluster job requirement. 
.PP
.SS "#define PEND_AC_BAD_PROV_REQ   6804"
.PP
Invalid Dynamic Cluster provisioning request. 
.PP
.SS "#define PEND_AC_PROV_REQ_FAIL   6805"
.PP
Failed to execute Dynamic Cluster job provisioning request. 
.PP
.SS "#define PEND_AC_LESS_MAXMEM   6806"
.PP
Dynamic Cluster server host does not have enough memory to satisfy job request. 
.PP
.SS "#define PEND_AC_VM_POWERINGOFF   6807"
.PP
Some virtual machines are shutting down on Dynamic Cluster host, cannot be used for scheduling. 
.PP
.SS "#define PEND_AC_UNUSE_SLOTS   6808"
.PP
Dynamic Cluster host does not have enough job slots because some virtual machine jobs are in the middle of provisioning operations. 
.PP
.SS "#define PEND_HOST_NO_AC_PLUGIN   6809"
.PP
LSF scheduler cannot schedule jobs to use Dynamic Cluster hosts because the Dynamic Cluster scheduling plugin is not configured or not loaded. 
.PP
.SS "#define PEND_AC_ACJOB_PREEMPTED   6810"
.PP
Dynamic Cluster virtual machine image is saved, job is waiting for rescheduling. 
.PP
.SS "#define PEND_AC_ACJOB_RESTORE_FAIL   6811"
.PP
Failed to restore the Dynamic Cluster virtual machine image, job is waiting for rescheduling. 
.PP
.SS "#define PEND_AC_FAIL_CREATE_REQ   6812"
.PP
Failed to create the Dynamic Cluster machine provisioning request. 
.PP
.SS "#define PEND_AC_RESTOREVM_NOT_SAME_RESGROUP   6813"
.PP
Dynamic Cluster host does not belong to the same resource group and cannot be used to restore the saved virtual machine. 
.PP
.SS "#define PEND_AC_RESTOREVM_NOT_ACHOST   6814"
.PP
Host is not a Dynamic Cluster host and cannot be used to restore saved virtual machines. 
.PP
.SS "#define PEND_AC_HOST_NO_VM_TEMPLATE   6815"
.PP
Dynamic Cluster host does not have virtual machines for the job-required template or does not allow creating virtual machines for the specified template. 
.PP
.SS "#define PEND_AC_PM_INPROVISIONING   6816"
.PP
Dynamic Cluster host is powering on or under provisioning. 
.PP
.SS "#define PEND_AC_HOST_PM_TEMPLATE_NOMATCH   6817"
.PP
Dynamic Cluster host template does not match job requirements. 
.PP
.SS "#define PEND_AC_PM_RESERVE_TEMPLATE   6018"
.PP
Dynamic Cluster host has been reserved by a job with different physical machine templates. 
.PP
.SS "#define PEND_AC_NOT_READY   6819"
.PP
Dynamic Cluster host is not up and running. 
.PP
.SS "#define PEND_AC_HOST_NOT_EMPTY   6820"
.PP
Cannot re-provision the Dynamic Cluster host because it has running jobs. 
.PP
.SS "#define PEND_AC_LSF_NOT_READY   6821"
.PP
LSF daemons on the Dynamic Cluster host are not ready to accept jobs. 
.PP
.SS "#define PEND_AC_TTL_NOTEXPIRED   6822"
.PP
Dynamic Cluster host does not have enough resources because the idle virtual machines cannot be re-provisioned to meet the job requirements: There are idle virtual machines with a time to live that are not yet expired. 
.PP
.SS "#define PEND_AC_JOB_VM_NOSUSPENDED   6823"
.PP
Dynamic Cluster virtual machine job cannot be restored because it is not in a suspended state. 
.PP
.SS "#define PEND_AC_UNABLE_REPROVISIONING   6824"
.PP
Unable to start re-provisioning. 
.PP
.SS "#define PEND_AC_VMJOB_TOO_BIG_MEMSIZE   6825"
.PP
The memory requirement is larger than the amount that Dynamic Cluster currently offers. 
.PP
.SS "#define PEND_AC_HOST_INELIGIBLE_FOR_REPROVISION   6826"
.PP
Ineligible for re-provisioning due to the threshold for failed provisioning attempts. 
.PP
.SS "#define PEND_AC_TTL_NOTEXPIRED_ACHOST   6827"
.PP
Unable to re-provision due to the value of the DC_MACHINE_MIN_TTL parameter. 
.PP
.SS "#define PEND_AC_RMT_TEMPLATE_NOT_FOUND   6828"
.PP
Dynamic Cluster template is not found in the remote cluster. 
.PP
.SS "#define PEND_AC_NOT_HYPERVISOR   6829"
.PP
Host is not a Dynamic Cluster hypervisor. 
.PP
.SS "#define PEND_AC_TOO_BIG_MEMSIZE_VM_ON_HV   6830"
.PP
Dynamic Cluster hypervisor cannot provide a virtual machine with the job's resource (mem) requirement larger than the amount that Dynamic Cluster currently offers. 
.PP
.SS "#define PEND_AC_HOST_RESREQ_COMPOUND   6831"
.PP
Dynamic Cluster hosts cannot be used to satisfy compound or alternative resource requirements. 
.PP
.SS "#define PEND_AC_VMJOB_RESREQ_COMPOUND   6832"
.PP
Dynamic Cluster VM jobs cannot use compound or alternative resource requirements. 
.PP
.SS "#define PEND_AC_ACJOB_RESTART   6833"
.PP
Dynamic Cluster virtual machine job is restarting. 
.PP
.SS "#define PEND_AC_ACJOB_RESTART_FAIL   6834"
.PP
Failed to restart the Dynamic Cluster virtual machine checkpoint, job is waiting for rescheduling. 
.PP
.SS "#define PEND_AC_USER_HOST_FILE   6835"
.PP
User-specified host file cannot include Dynamic Cluster job requirements. 
.PP
.SS "#define PEND_DS_NO_SPACE   6901"
.PP
Host does not have enough storage space. 
.PP
.SS "#define PEND_DS_NO_ACCESS   6902"
.PP
Host cannot access dataset. 
.PP
.SS "#define PEND_DS_STORAGE_UNAVAIL   6903"
.PP
The storage that the host can access is not available. 
.PP
.SS "#define PEND_DS_STORAGE_CLOSE   6904"
.PP
The storage that the host can access is closed. 
.PP
.SS "#define PEND_DS_UNREG_DATASET   6905"
.PP
The dataset is not registered. 
.PP
.SS "#define PEND_DS_NO_CLOSEST_STORAGE   6906"
.PP
Host has no close storage. 
.PP
.SS "#define PEND_DS_SYNTAX_ERROR   6907"
.PP
Syntax error in -extsched option. 
.PP
.SS "#define PEND_HOST_JOB_RUSAGE_THRESHOLD   7101"
.PP
Job requirements for threshold of resource not satisfied. 
.PP
.SS "#define PEND_NETWORK_WINDOW_LIMIT   7401"
.PP
Not enough windows on the network. 
.PP
.SS "#define PEND_NETWORK_JOB_DEDICATED   7402"
.PP
Dedicated job cannot run because the network is occupied by another POE job. 
.PP
.SS "#define PEND_NETWORK_WINDOW_DEDICATED   7403"
.PP
Network window is occupied by another dedicated POE job. 
.PP
.SS "#define PEND_NETWORK_WINDOW_FAILED   7404"
.PP
Network cannot be used due to network failure. 
.PP
.SS "#define PEND_FWD_NETWORK_REQ   7405"
.PP
Forwarding a job with a network requirement to a remote cluster running an LSF version prior to 9.1.1 is not supported. 
.PP
.SS "#define PEND_NETWORK_EXCEED_MAX_PROTOCOL_INSTANCE   7406"
.PP
Job requests more network window instances than MAX_PROTOCOL_INSTANCES. 
.PP
.SS "#define PEND_NETWORK_CHKPNT   7407"
.PP
Job with network requirement cannot be checkpointed. 
.PP
.SS "#define PEND_NETWORK_DISABLED   7408"
.PP
Network aware scheduling feature is not enabled. 
.PP
.SS "#define PEND_NETWORK_LEASE_IN_HOST   7409"
.PP
Cannot run POE job on lease-in host. 
.PP
.SS "#define PEND_HOST_QUEUE_PRE_FAIL   7430"
.PP
The job's host-based queue level pre-exec command exited with non-zero status. 
.PP
.SS "#define PEND_HOST_APP_PRE_FAIL   7431"
.PP
The job's host-based application level pre-exec command exited with non-zero status. 
.PP
.SS "#define PEND_START_MPS_DAEMON_FAIL   7432"
.PP
The MPS daemon command exited with non-zero status. 
.PP
.SS "#define PEND_GPU_MODE_CHANGE_FAILED   7433"
.PP
GPU mode change failed. 
.PP
.SS "#define PEND_GPU_CHECK_FAIL   7434"
.PP
The job's GPU check fail. 
.PP
.SS "#define PEND_GPU_HOST_NOT_SUPPORT   7435"
.PP
The sbatchd or lim on the host doesn't support GPU jobs. 
.PP
.SS "#define PEND_MANAGE_FREQUENCY_DISABLED   7450"
.PP
CPU frequency management is disabled. 
.PP
Job cannot request a CPU frequency 
.SS "#define PEND_FREQUENCY_EXCLUSIVE   7451"
.PP
LSF_MANAGE_FREQUENCY=HOST in lsf.conf. 
.PP
Job requires exclusive use (bsub -x) of host 
.SS "#define PEND_FREQUENCY_BY_CORE   7452"
.PP
LSF_MANAGE_FREQUENCY=CORE in lsf.conf. 
.PP
Job must be submitted with affinity resource requirements 
.SS "#define PEND_AUTORESIZE_EAS_JOB   7453"
.PP
CPU Frequency/Energy collection job does not automatically resize. 
.PP

.SS "#define PEND_GENERATE_OR_AUTO_FREQ_DISABLE   7454"
.PP
Energy policy tag generation and automatic CPU frequency selection is disabled. 
.PP
Job cannot request tag generation or automatic CPU frequency selection 
.SS "#define PEND_GENERATE_OR_AUTO_FREQ_EXCLUSIVE   7455"
.PP
Jobs requiring energy policy tag generation or automatic CPU frequency selection require exclusive use (bsub -x) of the host. 
.PP
.SS "#define PEND_DATA_WAITING_FOR_STAGING   7500"
.PP
Job is waiting for its data requirement to be satisfied. 
.PP
.SS "#define PEND_WAITING_FOR_PLANNED_ALLOCATION   7501"
.PP
Job is waiting for a planned allocation. 
.PP
.SS "#define PEND_JOB_EXCEEDED_FAILED_TRANSFER_JOB_LIMIT   7502"
.PP
Too many stage-in jobs have failed for this job. 
.PP
.SS "#define PEND_HOST_NOT_IN_PLAN   7503"
.PP
Host not allocated in the planned allocation. 
.PP
.SS "#define PEND_EXTSCHED_HOST_FILE   7600"
.PP
User-specified host file cannot be combined with external scheduling options. 
.PP
.SS "#define PEND_GENERAL_LIMIT_APP   7700"
.PP
Resource limit defined on application has been reached. 
.PP
.SS "#define PEND_GENERAL_LIMIT_APP_END   8000"
.PP
place holder for limit reason for application 
.PP
.SS "#define PEND_CUSTOMER_MIN   20001"
.PP
Customized pending reason number between min and max. 
.PP

.SS "#define PEND_CUSTOMER_MAX   25000"
.PP
Customized pending reason number between min and max. 
.PP

.SS "#define PEND_MAX_REASONS   25001"
.PP
The maximum number of reasons. 
.PP
.ad l
.nh
.SH NAME
suspending_reasons \- suspending_reasons is part of pending_reasons  

.PP
.SS "Defines"

.in +1c
.ti -1c
.RI "#define \fBSUSP_USER_REASON\fP   0x00000000"
.br
.ti -1c
.RI "#define \fBSUSP_USER_RESUME\fP   0x00000001"
.br
.ti -1c
.RI "#define \fBSUSP_USER_STOP\fP   0x00000002"
.br
.ti -1c
.RI "#define \fBSUSP_QUEUE_REASON\fP   0x00000004"
.br
.ti -1c
.RI "#define \fBSUSP_QUEUE_WINDOW\fP   0x00000008"
.br
.ti -1c
.RI "#define \fBSUSP_RESCHED_PREEMPT\fP   0x00000010"
.br
.ti -1c
.RI "#define \fBSUSP_HOST_LOCK\fP   0x00000020"
.br
.ti -1c
.RI "#define \fBSUSP_LOAD_REASON\fP   0x00000040"
.br
.ti -1c
.RI "#define \fBSUSP_MBD_PREEMPT\fP   0x00000080"
.br
.ti -1c
.RI "#define \fBSUSP_SBD_PREEMPT\fP   0x00000100"
.br
.ti -1c
.RI "#define \fBSUSP_QUE_STOP_COND\fP   0x00000200"
.br
.ti -1c
.RI "#define \fBSUSP_QUE_RESUME_COND\fP   0x00000400"
.br
.ti -1c
.RI "#define \fBSUSP_PG_IT\fP   0x00000800"
.br
.ti -1c
.RI "#define \fBSUSP_REASON_RESET\fP   0x00001000"
.br
.ti -1c
.RI "#define \fBSUSP_LOAD_UNAVAIL\fP   0x00002000"
.br
.ti -1c
.RI "#define \fBSUSP_ADMIN_STOP\fP   0x00004000"
.br
.ti -1c
.RI "#define \fBSUSP_RES_RESERVE\fP   0x00008000"
.br
.ti -1c
.RI "#define \fBSUSP_MBD_LOCK\fP   0x00010000"
.br
.ti -1c
.RI "#define \fBSUSP_RES_LIMIT\fP   0x00020000"
.br
.ti -1c
.RI "#define \fBSUSP_SBD_STARTUP\fP   0x00040000"
.br
.ti -1c
.RI "#define \fBSUSP_HOST_LOCK_MASTER\fP   0x00080000"
.br
.ti -1c
.RI "#define \fBSUSP_HOST_RSVACTIVE\fP   0x00100000"
.br
.ti -1c
.RI "#define \fBSUSP_DETAILED_SUBREASON\fP   0x00200000"
.br
.ti -1c
.RI "#define \fBSUSP_GLB_LICENSE_PREEMPT\fP   0x00400000"
.br
.ti -1c
.RI "#define \fBSUSP_CRAYX1_POSTED\fP   0x00800000"
.br
.ti -1c
.RI "#define \fBSUSP_ADVRSV_EXPIRED\fP   0x01000000"
.br
.ti -1c
.RI "#define \fBSUSP_STOP_RELEASE_JOB_SLOT\fP   0x02000000"
.br
.in -1c
.SH "Detailed Description"
.PP 
suspending_reasons is part of pending_reasons 
.SH "Define Documentation"
.PP 
.SS "#define SUSP_USER_REASON   0x00000000"
.PP
Virtual code. 
.PP
Not a reason 
.SS "#define SUSP_USER_RESUME   0x00000001"
.PP
The job is waiting to be re-scheduled after being resumed by the user. 
.PP

.SS "#define SUSP_USER_STOP   0x00000002"
.PP
The user suspended the job. 
.PP

.SS "#define SUSP_QUEUE_REASON   0x00000004"
.PP
Virtual code. 
.PP
Not a reason 
.SS "#define SUSP_QUEUE_WINDOW   0x00000008"
.PP
The run window of the queue is closed. 
.PP

.SS "#define SUSP_RESCHED_PREEMPT   0x00000010"
.PP
Suspended after preemption. 
.PP
The system needs to re-allocate CPU utilization by job priority. 
.SS "#define SUSP_HOST_LOCK   0x00000020"
.PP
The LSF administrator has locked the execution host. 
.PP

.SS "#define SUSP_LOAD_REASON   0x00000040"
.PP
A load index exceeds its threshold. 
.PP
The subreasons field indicates which indices. 
.SS "#define SUSP_MBD_PREEMPT   0x00000080"
.PP
The job was preempted by mbatchd because of a higher priorty job. 
.PP

.SS "#define SUSP_SBD_PREEMPT   0x00000100"
.PP
Preempted by sbatchd. 
.PP
The job limit of the host/user has been reached. 
.SS "#define SUSP_QUE_STOP_COND   0x00000200"
.PP
The suspend conditions of the queue, as specified by the STOP_COND parameter in lsb.queues, are true. 
.PP

.SS "#define SUSP_QUE_RESUME_COND   0x00000400"
.PP
The resume conditions of the queue, as specified by the RESUME_COND parameter in lsb.queues, are false. 
.PP

.SS "#define SUSP_PG_IT   0x00000800"
.PP
The job was suspended due to the paging rate and the host is not idle yet. 
.PP

.SS "#define SUSP_REASON_RESET   0x00001000"
.PP
Resets the previous reason. 
.PP

.SS "#define SUSP_LOAD_UNAVAIL   0x00002000"
.PP
Load information on the execution hosts is unavailable. 
.PP

.SS "#define SUSP_ADMIN_STOP   0x00004000"
.PP
The job was suspened by root or the LSF administrator. 
.PP

.SS "#define SUSP_RES_RESERVE   0x00008000"
.PP
The job is terminated due to resource limit. 
.PP

.SS "#define SUSP_MBD_LOCK   0x00010000"
.PP
The job is locked by the mbatchd. 
.PP

.SS "#define SUSP_RES_LIMIT   0x00020000"
.PP
The job's requirements for resource reservation are not satisfied. 
.PP

.SS "#define SUSP_SBD_STARTUP   0x00040000"
.PP
The job is suspended while the sbatchd is restarting. 
.PP

.SS "#define SUSP_HOST_LOCK_MASTER   0x00080000"
.PP
The execution host is locked by the master LIM. 
.PP

.SS "#define SUSP_HOST_RSVACTIVE   0x00100000"
.PP
An advance reservation using the host is active. 
.PP
.SS "#define SUSP_DETAILED_SUBREASON   0x00200000"
.PP
There is a detailed reason in the subreason field. 
.PP
.SS "#define SUSP_GLB_LICENSE_PREEMPT   0x00400000"
.PP
The job is preempted by glb. 
.PP
.SS "#define SUSP_CRAYX1_POSTED   0x00800000"
.PP
Job not placed by Cray X1 psched. 
.PP
.SS "#define SUSP_ADVRSV_EXPIRED   0x01000000"
.PP
Job suspended when its advance reservation expired. 
.PP
.SS "#define SUSP_STOP_RELEASE_JOB_SLOT   0x02000000"
.PP
bstop release job slot 
.PP
.ad l
.nh
.SH NAME
suspending_subreasons \- suspending_subreasons has the following options:  

.PP
.SS "Defines"

.in +1c
.ti -1c
.RI "#define \fBSUB_REASON_RUNLIMIT\fP   0x00000001"
.br
.ti -1c
.RI "#define \fBSUB_REASON_DEADLINE\fP   0x00000002"
.br
.ti -1c
.RI "#define \fBSUB_REASON_PROCESSLIMIT\fP   0x00000004"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CPULIMIT\fP   0x00000008"
.br
.ti -1c
.RI "#define \fBSUB_REASON_MEMLIMIT\fP   0x00000010"
.br
.ti -1c
.RI "#define \fBSUB_REASON_THREADLIMIT\fP   0x00000020"
.br
.ti -1c
.RI "#define \fBSUB_REASON_SWAPLIMIT\fP   0x00000040"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_ACCOUNTID\fP   0x00000001"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_ATTRIBUTE\fP   0x00000002"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_BLOCKED\fP   0x00000004"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_RESTART\fP   0x00000008"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_DEPTH\fP   0x00000010"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_GID\fP   0x00000020"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_GASID\fP   0x00000040"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_HARDLABEL\fP   0x00000080"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_LIMIT\fP   0x00000100"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_MEMORY\fP   0x00000200"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_SOFTLABEL\fP   0x00000400"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_SIZE\fP   0x00000800"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_TIME\fP   0x00001000"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_UID\fP   0x00002000"
.br
.ti -1c
.RI "#define \fBSUB_REASON_CRAYX1_WIDTH\fP   0x00004000"
.br
.in -1c
.SH "Detailed Description"
.PP 
suspending_subreasons has the following options: 
.SH "Define Documentation"
.PP 
.SS "#define SUB_REASON_RUNLIMIT   0x00000001"
.PP
Sub reason of SUSP_RES_LIMIT: RUNLIMIT is reached. 
.PP

.SS "#define SUB_REASON_DEADLINE   0x00000002"
.PP
Sub reason of SUSP_RES_LIMIT: DEADLINE is reached. 
.PP

.SS "#define SUB_REASON_PROCESSLIMIT   0x00000004"
.PP
Sub reason of SUSP_RES_LIMIT: PROCESSLIMIT is reached. 
.PP

.SS "#define SUB_REASON_CPULIMIT   0x00000008"
.PP
Sub reason of SUSP_RES_LIMIT: CPULIMIT is reached. 
.PP

.SS "#define SUB_REASON_MEMLIMIT   0x00000010"
.PP
Sub reason of SUSP_RES_LIMIT: MEMLIMIT is reached. 
.PP

.SS "#define SUB_REASON_THREADLIMIT   0x00000020"
.PP
Sub reason of SUSP_RES_LIMIT: THREADLIMIT is reached. 
.PP

.SS "#define SUB_REASON_SWAPLIMIT   0x00000040"
.PP
Sub reason of SUSP_RES_LIMIT: SWAPLIMIT is reached. 
.PP

.SS "#define SUB_REASON_CRAYX1_ACCOUNTID   0x00000001"
.PP
Account ID does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_ATTRIBUTE   0x00000002"
.PP
Attribute does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_BLOCKED   0x00000004"
.PP
Blocked by one or more gates. 
.PP
.SS "#define SUB_REASON_CRAYX1_RESTART   0x00000008"
.PP
Application is in the process of being restarted and it is under the control of CPR. 
.PP
.SS "#define SUB_REASON_CRAYX1_DEPTH   0x00000010"
.PP
Depth does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_GID   0x00000020"
.PP
GID does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_GASID   0x00000040"
.PP
No GASID is available. 
.PP
.SS "#define SUB_REASON_CRAYX1_HARDLABEL   0x00000080"
.PP
Hard label does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_LIMIT   0x00000100"
.PP
Limit exceeded in regions or domains. 
.PP
.SS "#define SUB_REASON_CRAYX1_MEMORY   0x00000200"
.PP
Memory size does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_SOFTLABEL   0x00000400"
.PP
Soft label does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_SIZE   0x00000800"
.PP
Size gate (width times depth larger than gate allows). 
.PP
.SS "#define SUB_REASON_CRAYX1_TIME   0x00001000"
.PP
Time limit does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_UID   0x00002000"
.PP
UID does not match those allowed by the gate. 
.PP
.SS "#define SUB_REASON_CRAYX1_WIDTH   0x00004000"
.PP
Width does not match those allowed by the gate. 
.PP
.SH "Author"
.PP 
Generated automatically by Doxygen for IBM Spectrum LSF 10.1 C API Reference from the source code.

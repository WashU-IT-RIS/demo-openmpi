
.ad l

.TH pam 1 "July 2021" "" ""
.ll 72

.ce 1000
\fBpam\fR
.ce 0

.sp 2
Parallel Application Manager â€“ job starter for MPI applications
.sp 2

.SH HP-UX vendor MPI syntax

.sp 2
\fBbsub pam -mpi mpirun\fR [mpirun_options] mpi_app [argument
 ...]
.SH Generic PJL framework syntax

.sp 2
\fBbsub pam\fR [\fB-t\fR] [\fB-v\fR] [\fB-n\fR num_tasks]
\fB-g\fR [num_args] pjl_wrapper [pjl_options] mpi_app [argument
 ...] \fBpam\fR [\fB-h\fR] \fBpam\fR [\fB-V\fR]
.SH Description

.sp 2
The Parallel Application Manager (PAM) is fully integrated with
LSF. PAM acts as the supervisor of a parallel LSF job.
.sp 2
MPI jobs started by the pam command can be submitted only through
batch jobs, PAM cannot be used interactively to start parallel
jobs. The sbatchd daemon starts PAM on the first execution host.
.sp 2
PAM has the following functionality for all parallel application
processes (tasks):
.sp 2
*  Uses a vendor MPI library or an MPI Parallel Job Launcher
   (PJL), for example, mpirun or poe, to start a parallel job on
   a specified set of hosts in an LSF cluster.
.sp 2
*  PAM contacts RES on each execution host that is allocated to
   the parallel job.
.sp 2
*  PAM queries RES periodically to collect resource usage for
   each parallel task and passes control signals through RES to
   all process groups and individual running tasks, and cleans up
   tasks as needed.
.sp 2
*  Passes job-level resource usage and process IDs (PIDs and
   PGIDs) to sbatchd for enforcement
.sp 2
*  Collects resource usage information and exit status upon
   termination
.SH Task startup for vendor MPI jobs

.sp 2
The pam command starts a vendor MPI job on a specified set of
hosts in an LSF cluster. The pam command that starts an MPI job
requires the underlying MPI system to be LSF-aware, using a
vendor MPI implementation that supports LSF (for example, HP-UX
vendor MPI).
.sp 2
PAM uses the vendor MPI library to create the child processes
needed for the parallel tasks that make up your MPI application.
It starts these tasks on the systems that are allocated by LSF.
The allocation includes the number of execution hosts needed, and
the number of child processes needed on each host.
.SH Task startup for generic PJL jobs

.sp 2
For parallel jobs submitted with bsub:
.sp 2
*  PAM starts the PJL, which in turn starts the TaskStarter (TS).
.sp 2
*  TS starts the tasks on each execution host, reports the
   process ID to PAM, and waits for the task to finish.
.sp 2
Two environment variables enable PAM to run scripts or binary
files before or after PAM is started. These variables are useful
if you customize the mpirun.lsf script and have job scripts that
call the mpirun.lsf script more than once.
.sp 2
\fB\fB$MPIRUN_LSF_PRE_EXEC\fB\fR
.br
         Runs before PAM is started.
.sp 2
\fB\fB$MPIRUN_LSF_POST_EXEC\fB\fR
.br
         Runs after PAM is started.
.SH Options for vendor MPI jobs

.sp 2
\fB-auto_place\fR
.br
         The -auto_place option on the pam command line tells the
         IRIX mpirun library to start the MPI application
         according to the resources allocated by LSF.
.sp 2
\fB-mpi\fR
.br
         On HP-UX, you can have LSF manage the allocation of
         hosts to achieve better resource usage by coordinating
         the start-up phase with the mpirun command. Precede the
         regular MPI mpirun command with the following command:
.sp 2
         bsub pam -mpi
.sp 2
         For HP-UX vendor MPI jobs, the -mpi option must be the
         first option of the pam command.
.sp 2
         For example, the following mpirun command runs a
         single-host job:
.sp 2
         mpirun -np 14 a.out
.sp 2
         To have LSF select the host, include the mpirun command
         in the bsub job submission command:
.sp 2
         bsub pam -mpi mpirun -np 14 a.out
.sp 2
\fB-n \fInum_tasks\fB\fR
.br
         The number of processors that are required to run the
         parallel application, typically the same as the number
         of parallel tasks in the job. If the host is a
         multiprocessor, one host can start several tasks.
.sp 2
         You can use both the bsub -n and pam -n commands in the
         same job submission. The number that is specified in the
         pam -n option must be less than or equal to the number
         specified by the bsub -n command. If the number of tasks
         that are specified with the pam -n command is greater
         than the number that is specified by the bsub -n
         command, the pam -n command is ignored.
.sp 2
         For example, you can specify the following command:
.sp 2
         bsub -n 5 pam -n 2 -mpi -auto_place a.out
.sp 2
         The job requests five processors, but PAM starts only
         two parallel tasks.
.sp 2
\fB\fImpi_app\fB [\fIargument\fB ...]\fR
.br
         The name of the MPI application to be run on the listed
         hosts. This name must be the last argument on the
         command line.
.sp 2
\fB-h\fR
.br
         Prints command usage to stderr and exit.
.sp 2
\fB-V\fR
.br
         Prints LSF release version to stderr and exit.
.SH Options for generic PJL jobs

.sp 2
\fB-t\fR
.br
         This option tells the pam command not to print the MPI
         job tasks summary report to the standard output. By
         default, the summary report prints the task ID, the host
         that it ran on, the command that was run, the exit
         status, and the termination time.
.sp 2
\fB-v\fR
.br
         Verbose mode. Displays the name of the execution host or
         hosts.
.sp 2
\fB-g [\fInum_args\fB] \fIpjl_wrapper\fB [\fIpjl_options\fB] \fR
.br
         The -g option is required to use the generic PJL
         framework. You must specify all the other pam options
         before -g.
.sp 2
         \fB\fR\fInum_args\fR\fB\fR
.br
                  Specifies how many space-separated arguments in
                  the command line are related to the PJL (after
                  that, the remaining section of the command line
                  is assumed to be related to the binary
                  application that starts the parallel tasks).
.sp 2
         \fB\fR\fIpjl_wrapper\fR\fB\fR
.br
                  The name of the PJL.
.sp 2
         \fB\fR\fIpjl_options\fR\fB\fR
.br
                  Optional arguments to the PJL.
.sp 2
         For example:
.sp 2
         *  A PJL named \fRno_arg_pjl\fR takes no options, so
            \fInum_args\fR=1. The syntax is:
.sp 2
            pam [pam_options] -g 1 no_arg_pjl job [job_options]
.br

.sp 2
         *  A PJL is named 3_arg_pjl and takes the options -a,
            -b, and \fIgroup_name\fR, so \fInum_args\fR=4. Use
            the following syntax:
.sp 2
            pam [pam_options] -g 4 3_arg_pjl -a -b group_name job [job_options]
.br

.sp 2
\fB-n \fInum_tasks\fB\fR
.br
         The number of processors that are required to run the
         MPI application, typically the number of parallel tasks
         in the job. If the host is a multiprocessor, one host
         can start several tasks.
.sp 2
         You can use both the bsub -n and pam -n commands in the
         same job submission. The number that is specified in the
         pam -n option must be less than or equal to the number
         specified by the bsub -n option. If the number of tasks
         that are specified with the pam -n option is greater
         than the number specified by the bsub -n option, the pam
         -n option is ignored.
.sp 2
\fB\fImpi_app\fB [\fIargument \fB ...]\fR
.br
         The name of the MPI application to be run on the listed
         hosts. This name must be the last argument on the
         command line.
.sp 2
\fB-h\fR
.br
         Prints command usage to stderr and exit.
.sp 2
\fB-V\fR
.br
         Prints LSF release version to stderr and exits.
.SH Exit Status

.sp 2
The pam command exits with the exit status of the mpirun command
or the PJL wrapper.
.SH See also

.sp 2
bsub